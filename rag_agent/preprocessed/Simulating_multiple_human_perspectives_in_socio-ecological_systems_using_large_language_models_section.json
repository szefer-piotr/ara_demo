[
  {
    "heading": "Simulating multiple human perspectives in socio-ecological systems using",
    "content": "large language models \n \nYongchao Zeng1,*, Calum Brown 1,2, Ioannis Kyriakou3,*, Ronja Hotz1, Mark Rounsevell1,4,5 \n1 Institute of Meteorology and Climate Research, Atmospheric Environmental Research (IMK-IFU), \nKarlsruhe Institute of Technology, 82467 Garmisch-Partenkirchen, Germany \n2 Highlands Rewilding Limited, The Old School House, Bunloit, Drumnadrochit IV63 6XG, UK \n3 Bayes Business School, City St George's, University of London, London EC1V 0HB,UK \n4 Institute of Geography and Geo-ecology, Karlsruhe Institute of Technology, 76131 Karlsruhe, Germany \n5 School of Geosciences, University of Edinburgh, Drummond Street, Edinburgh EH8 9XP, UK \n \n* Corresponding author"
  },
  {
    "heading": "E-mail address: yongchao.zeng@kit.edu (Y. Zeng)",
    "content": "ioannis.kyriakou.2@citystgeorges.ac.uk (I. Kyriakou) \n \nAbstract Understanding socio-ecological systems requires insights from diverse stakeholder \nperspectives, which are often hard to access. To enable alternative, simulation-based exploration \nof different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective \nShifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) \nto represent various stakeholders; users can step into the agent roles to experience perspectival \ndifferences. A simulation protocol serves as a \u201cscaffold\u201d to streamline multiple perspective-taking \nsimulations, supporting users in reflecting on, transitioning between, and integrating across \nperspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional \ndynamics and land use change, enabling both narrative-driven and numerical experiments. In an \nillustrative experiment, a user successively adopts the perspectives of a system observer and a \nresearcher \u2013 a role that analyses data from the embedded land use model to inform evidence-based \ndecision-making for other LLM agents representing various institutions. Despite the user\u2019s effort \nto recommend technically sound policies, discrepancies persist between the policy \nrecommendation and implementation due to stakeholders\u2019 competing advocacies, mirroring real-\nworld misalignment between researcher and policymaker perspectives. The user\u2019s reflection \nhighlights the subjective feelings of frustration and disappointment as a researcher, especially due \nto the challenge of maintaining political neutrality while attempting to gain political influence. \nDespite this, the user exhibits high motivation to experiment with alternative narrative framing \nstrategies, suggesting the system\u2019s potential in exploring different perspectives. Further system and \nprotocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-\necological simulations. \nKeywords: perspective-taking, situated knowledge, LLM, socio-ecological modelling, agent \n \n1. Introduction \nIn the closing scene of The Lives of Others (Henckel von Donnersmarck, 2006), a former East \nGerman surveillance officer walks into a bookstore and finds a novel written by someone he once \nmonitored. In his previous role, he was an observer, supposed to maintain analytical and emotional \nneutrality. However, as time went on, his surveillance drew him deeper into the emotions of his \nmonitored subjects. The feelings of fear, love, and struggle gradually converted him from a passive \nobserver into an active participant. Beyond the fictional world, the movie captures an important \ninsight: perspective matters, and it shapes not just our perceptions but also our understanding, \ndecision-making, and actions. Social psychology literature demonstrates that taking on alternative \nperspectives profoundly affects moral judgment (Young, 2018), empathy (Todd and Galinsky, \n2014), negotiation strategy (Galinsky et al., 2008; Ku et al., 2015), and even influences long-term \nattitude (Hall et al., 2021). In cognitive sciences, the situated cognition theory highlights further \nthat knowledge is not abstract, detached from context (Brown et al., 1989); instead, it is a process \nheavily influenced by the positions one takes up and the social system one inhabits (Lave and"
  },
  {
    "heading": "Wenger, 1991).",
    "content": "Literature shows that perspective-taking and situated knowledge are not only crucial for social \npsychology research but may also provide valuable insights to inform socio-ecological simulation \n(Chen and Martin, 2015; Danielsen et al., 2000; Reed et al., 2010; Selfa et al., 2022; Wedding et \nal., 2024), where modelling human behaviours is a substantial challenge (Filatova et al., 2013). \nSocio-ecological systems consist of interacting human and natural processes. Integrating \nperspectival nuances into simulations makes this challenge more formidable, as it demands a \nsocially vivid virtual environment to evoke complex human behaviours. To simulate the socio-\necological duality, models must account for not only rule-based structures but also linguistic, \nperspective-rich interactions. Despite methodological overlap, a spectrum of methods can be \nidentified according to their typical use cases in modelling human-involved systems, ranging from \nagent-based modelling (Filatova et al., 2013) to participatory (Becu et al., 2017; Gilbert et al., 2002) \nand role-playing simulations (Rumore et al., 2016), each varying in their reliance on formal rules \nversus natural language, and in how they represent social versus ecological dimensions.  \nAt one end of the spectrum, agent-based modelling (ABM) often uses decision rules to simulate \nindependent agents and enable pattern emergence at the system level (Heckbert et al., 2010). ABM \nexcels at integrating ecological processes (Schulze et al., 2017). However, with a simplified \nrepresentation of human behaviour, some researchers argue that it offers limited realism of social \ninteraction (Templeton et al., 2024). In the middle of the spectrum, participatory simulation can be \nincorporated as the last phase of participatory modelling (Voinov and Bousquet, 2010), when \nstakeholder interactions are mediated through \u201cthe rules of the game\u201d (Becu et al., 2017; Voinov \nand Bousquet, 2010). These simulations have higher social realism from human participant \nengagement, with interactions still limited to pre-defined action spaces. Such an architecture \nsupports integration with models of natural systems but constrains expressive, situated human \nbehaviour. Role-playing simulation, at the opposite end of the spectrum to ABM, prioritises the \nmost highly open-ended, linguistically rich human interaction (Alejandro et al., 2024; Chen and \nMartin, 2015; Rumore et al., 2016). With this approach, social processes, such as dispute, \nnegotiation, and mutual understanding, can be vividly explored (Schinko and Bednar-Friedl, 2022). \nHowever, role-plays are resource-demanding, personnel-dependent, unsuitable for large-scale \nand/or long-time span simulation, and challenging to integrate with ecological models (Bring and \nLyon, 2019; Castella et al., 2005; Schinko and Bednar-Friedl, 2022). \nAcross this spectrum, there is a trade-off: as simulations become more linguistically expressive and \nsocially rich, their capacity to interface with natural processes weakens. Nevertheless, the need for \nperspective pluralism \u2013 to reflect how different stakeholders perceive and affect socio-ecological \nsystems \u2013 requires simulations that incorporate both narrative and numerical forms. Capturing \nethical dilemmas, communication subtleties, and culturally embedded values entails a \nmethodological shift toward hybrid models that bridge linguistic and rule-based representations to \nenable a more holistic simulation of coupled social and natural systems. \nThe recently developed large language models (LLMs) (Amaratunga, 2023; Naveed et al., 2023; \nZhao et al., 2023) bring new opportunities to address these challenges in socio-ecological \nsimulation (Zeng et al., 2025a). Unlike agents constrained strictly by pre-programmed rules or \nquantitative values, LLM-based agents are able to communicate, reason, and act through natural \nlanguage (Park et al., 2023; Qian et al., 2023; Sumers et al., 2023) \u2013 the same medium used by \nhumans to communicate to set goals, negotiate, persuade, or resist. Being properly prompted or \nfine-tuned, LLMs are capable of aligning with human actors in terms of personalities, political \nstances, and cultural identities (Argyle et al., 2023; Stampfl et al., 2024; Taubenfeld et al., 2024).  \nRecent controlled experiments demonstrated that LLMs prompted with personas have passed \nstandard three-party Turing tests (Jones and Bergen, 2025), indicating a high resemblance between \na real human interlocutor and an LLM-based agent. Linguistic competence makes it possible to \nmodel sophisticated behaviours that are challenging to model within hard-coded agent systems, \nenabling the representation of strategic ambiguity, framing in rhetoric, and conversational \ndynamics. More importantly, it allows greater facility in interacting smoothly with humans \n(Fragiadakis et al., 2024; Fui-Hoon Nah et al., 2023; Spillias et al., 2024). In addition, the rapid \nimprovement in structural LLM output and tool-calling features suggests the potential of building \nreusable interfaces that can effectively bridge the gap between linguistic and rule-based systems \n(Li et al., 2024; Luo et al., 2025; Shen, 2024; Xu et al., 2024). In effect, the emergence of LLMs \nallows the expansion of socio-ecological simulations from objective experimental spaces to \ninteractive, dialogical and perspective-holistic spaces in which roles are not merely represented but \nengaged directly. \nIn this paper, we propose the concept and explore the application of HoPeS \u2013 Human-oriented \nPerspective Shifting \u2013 a novel approach that enables model users to change perspectives by \nassuming the roles of different stakeholders in socio-ecological simulation. We first present the \nunderlying theoretical roots of HoPeS in situated knowledge and perspective-taking. The latter is \nseen as a basic building block of perspective-shifting, which is operationalised through a series of \nindividual but connected perspective-specific simulations. Based on this theoretical foundation, we \nelaborate on the architecture of the perspective-taking simulation system. Further, we propose a \nprotocol to navigate the simulation processes to achieve an integrated, systemic understanding.  \nAs a proof of concept, a prototype system is developed that incorporates two interconnected sub-\nsystems, respectively responsible for the perspective-taking simulation and AI-guided user \nreflection. The prototype system allows for multiple stakeholder agents driven by LLMs to interact \nand formulate policies to influence land use change. Dialogues are generated on the fly, which \ncreates open-ended interactions rather than scripted scenarios. Human users can step in to take up \nany of the roles of the stakeholders. Along with this, an AI \u201creflective companion\u201d guides users in \nreflecting on perspectives already taken, facilitating experiential learning and perspective \nintegration. Using this prototype, a stylised scenario experiment is conducted to illustrate how the \nsystem supports perspective-shifting simulations. As one of the key objectives of this research is \nto foster a broader conversation, encouraging research to experiment, discuss, and build upon the \nframework outlined here, we also reflect on key challenges that demand interdisciplinary \ncollaboration across diverse fields to drive future research forward. \n2. Theory \nThe complexity of socio-ecological systems stems partly from the nature of knowledge about such \nsystems. Haraway (1988) proposed the concept of \u201csituated knowledge\u201d and challenged the notion \nof \u201cobjectivity\u201d by pointing out the profound detachment of the so-called objective perspective \nfrom positionality, highlighting that all knowledge is affected by the position and context of the \nknower, including cultural background, affiliations, and life experiences. Knowledge is not a \nuniversal or objective truth, which therefore necessitates researchers\u2019 awareness of and reflection \non their biases (Haraway, 1988). \nThe importance of situated knowledge is particularly high in the domain of socio-ecological \nmodelling, where land use, governance, resource utilisation, and regulations are all shaped \ndynamically by the context, values, and power relations of various actors (Klein et al., 2024). \nResearchers in sustainability science have been increasingly aware of the fact that a singular \nperspective cannot capture full system complexities (Caniglia et al., 2023; Norstr\u00f6m et al., 2020; \nTeng\u00f6 et al., 2017). On the contrary, through perspective pluralism, including scientific, \ninstitutional, and experiential perspectives, we can approximate a holistic, systemic understanding. \nThus, researchers call for the integration of knowledge not only across disciplines but also across \ndifferent groups, whether policymakers, practitioners, or community members (Chambers et al., \n2021). \nWhile situated knowledge provides an epistemic framework, HoPeS makes this framework \noperational through perspective-taking, which refers to the cognitive and affective process of \nimagining the world from others\u2019 viewpoints (Galinsky et al., 2005). It is an active, intentional \neffort without being judgmental towards others\u2019 thoughts, emotions, and motives (Parker and \nAxtell, 2001). As an experimental method, perspective-taking is widely applied in psychology and \nbehavioural science (Ku et al., 2015). Perspective-taking is especially important in complex \nsystems which involve competing interests (Boca et al., 2018) and asymmetrical power (Gordon \nand Chen, 2013). Empirical research demonstrates that perspective-taking can reduce negative \nstereotypes (Wang et al., 2014) and improve negotiation outcomes (Gilin et al., 2013). Through a \ndifferent perspective, people can assume different roles, including those of underrepresented and \nmarginalised voices. Ku et al. (2015) proposed a model that specifies perspective-taking as a tool \nfor navigating across a mixed-motive world. The benefits of perspective-taking also underlie the \nincreasing use - and success - of \u2018serious games\u2019 in environmental systems management (Garcia et \nal., 2022). \nHoPeS is informed by the need for inclusivity, reflexivity, and perspective pluralism, enabling \nmodel users to gain perspectival experiences by stepping into others\u2019 roles and interacting with \nrelevant stakeholders emulated by LLM agents. Such perspectival experiences can help to uncover \nnuanced tensions, biases, and trade-offs that affect the modelling enterprise as well as practical \nreal-world decisions. Modelling itself is a situated process, influenced by the goals, hypotheses, \nand stances of modelling participants (Klein et al., 2024) and does not reproduce real-world \nphenomena from a detached, objective view. It can therefore make an important contribution to \nexploration and reflection; its utility hinges on what perspective it is encoded in and how users \nparticipate (Klein et al., 2024). HoPeS resonates with this idea by embedding perspective-taking \nwithin a dynamic, interactive simulation system. \n3. Methods \n3.1 The HoPeS framework  \nTo enable perspective-shifting simulation, the HoPeS framework incorporates two interconnected \ncomponents \u2013 LLM-powered perspective-taking simulation and a simulation protocol. The former \noutlines the architecture of a simulation system that allows for simulating human or human \norganisations through LLM agents; model users can step in and replace any of the LLM agents to \nparticipate in the simulation from the perspective of the replaced agents. The simulation protocol \nserves as a \u201cscaffold\u201d to streamline multiple perspective-taking simulations and supports model \nusers in reflecting on, transitioning between, and integrating across diverse perspectives. \n3.1.1 Architecture of perspective-taking simulation \nAs illustrated in Figure 1, the architecture of the perspective-taking simulation comprises three core \nprocedures: configuration, model execution, and output collection.  \nConfiguration is responsible for defining agent profiles, establishing inter-agent connections, and \nconfiguring visibility settings. This procedure also allows users to select a specific role they plan \nto assume during the simulation. Agent profiles serve as part of the input prompts for the language \nmodel and typically include the role\u2019s name, behavioural attributes, decision-making guidelines, \nexpected inputs and outputs. Connections between agents specify who can interact directly with \nwhom, as well as the pathways through which information flows. Visibility defines which agents\u2019 \noutputs are accessible to others. This element is essential for modelling social dynamics, as real-\nworld individuals often operate with incomplete information about others (Fischer and Stocken, \n2001; Smets, 1997).  \nModel Execution means running the model main loop, which comprises a social network \nrepresenting the connected LLM agents (including the agents controlled by users) and the \nenvironment that accommodates them. The social network facilitates interactions among agents, \nwhile the environment provides external, objective information relevant to their context. These two \nelements are dynamically coupled and evolve together. For example, the social network may \nconsist of agents representing decision-making bodies for land use policies, while the environment \ncomprises a land use model that both influences and is influenced by the agents\u2019 decisions. \nOutput collection is responsible for capturing the results of the simulation. Outputs may include \ndialogues between agents, reasoning processes, and decision-making trajectories. If the underlying \nlanguage model is multimodal or integrated with external tools, outputs may also encompass \nimages, plots, code, or even audio materials. Numerical data is mainly produced by the \nenvironment model. These outputs can be used to analyse system behaviour and to reflect on user \ninteraction and engagement with the simulation. \n \n \nFigure 1. LLM-powered architecture of perspective-taking simulation system \n3.1.2 Conceptual outline of the simulation protocol \nThe simulation protocol serves as a foundational element of the HoPeS framework. It is designed \nto facilitate users\u2019 engagement with multiple perspectives and to support user reflection and \nintegration of insights derived from perspective-shifting. The protocol includes a series of \nstructured procedures used before, during, and after simulation runs. Its overarching objective is to \nachieve perspective integration through bridging the individual perspective-taking simulations that \nusers have engaged in. The protocol should be transparent and adaptable to the specific aims of \nindividual experiments. Here, we conceptually outline the key procedures of the simulation \nprotocol as follows. \n1) Contextualization and perspective manipulation. A user is provided with a concise overview of \nthe simulated scenario, including the key roles, their interconnections, the information flow, the \nrole-environment interaction mechanism, and user tasks within the system. The user is also \ninformed about the roles\u2019 attributes, including, e.g., personas, political leaning, and constraints, \nsuch as narrative styles and tones.  \n2) Perspective-taking simulation. In this phase, the user starts the LLM-driven simulation system \nand participates in immersive role-play. The system logs all relevant outputs, including the user\u2019s \nand LLM agents\u2019 decisions, dialogues, internal reasoning states, and changes in the environment \nthe agents inhabit.  \n3) Perspective reflection. Based on the perspective-taking simulation, the user reflects on the \nexperiences, insights, and emotional responses developed through the simulation. The user may \nthen choose either to replay the same role to explore alternative responses of the role or to transition \nto a different role. \n4) Perspective transition. If the user opts to play a different role, a transition survey is entailed. \nThis survey helps users prepare for the next role based on the enhanced knowledge learned from \nthe prior role play. For instance, by taking the perspective of a policymaker, users might learn how \npolicymakers prioritise different goals, which can be used to better frame the narratives of a \nlobbyist in the next perspective-taking simulation.  \n5) Role iteration. Through iterative engagement across perspectives via the loop of perspective-\ntaking simulation, perspective reflection, and transition, users progressively build a deeper and \nmore sophisticated understanding of the driving factors, barriers, and even emotional experiences \nof individual decision-makers. \n7) Perspective integration. When the planned simulations are finished, the user comprehensively \nreflects on system dynamics, agent behaviour, and different perspectives the user has taken. The \nuser can take a \u201cmeta-perspective\u201d that sees the system together with users themselves as a whole \nfor analysis, comparing and synthesising the knowledge and experiences gained through \nperspective shifting. \n3.2 Prototype system \nBuilding on the framework outlined above, we developed a prototype to implement perspective-\nshifting simulations within a stylised but complex policy context of land use governance. The \nprototype is composed of two logically interconnected subsystems, implemented as separate \napplications using the Streamlit library (Python) (Streamlit, 2025), which offers an open-source \nframework particularly suitable for building minimum viable products (MVPs) (Stevenson et al., \n2024). Based on the sub-systems\u2019 core functionalities, we named them the Perspective-Taking \nSimulation (PTS) system and the Reflective Learning Companion (RLC) system. PTS enables \nusers to engage in real-time simulations, while RLC supports reflective learning. Both applications \nare powered by AI agents that guide and support users throughout the simulation and reflection \nprocesses. All AI agents are built using LangChain (2025) and LangGraph Python libraries \n(LangGraph, 2025). The land use model is coded in Java (Zeng, 2025c), and its interoperability \nwith the Python components is implemented using Py4J (2025).  \n \n \n3.2.1 Perspective-Taking Simulation (PTS) system \nAs illustrated in Figure 2, the overall structure of the PTS system has two major parts \u2013 the backend \nmodel and the frontend designed to interface human-AI interactions. A video demonstrating how \nthe PTS system works is provided at Zeng (2025d). \n \nFigure 2. The architecture of the prototype Perspective-Taking Simulation (PTS) system"
  },
  {
    "heading": "Backend",
    "content": "The backend model is driven by InsNet-CRAFTY (Zeng et al., 2024), which incorporates a social \nnetwork of institutional decision-making agents driven by LLMs and the CRAFTY land use model \n(Brown et al., 2017; Brown et al., 2018; Brown et al., 2019). The CRAFTY land use model serves \nas an environment with which the institutional agents can interact. In CRAFTY, different land users \nare simulated as agent functional types (AFTs), which are rule-based computational entities. An \nAFT has a unique matrix defining its efficiency in utilising different types of resources on the land \nit manages, through which the AFT produces a mix of ecosystem services, such as meat, crops, \ncarbon sequestration, and recreation. AFTs are motivated to compete for land that provides greater \nutility.  \nInstitutional interventions are activated subject to a policy time lag to influence the perceived utility \nof AFTs, which is intended to steer the land use change towards desired directions and hence adjust \nthe supply of different ecosystem services (Zeng et al., 2025b). Each of the institutional agents is \ndriven by a large language model and instructed by a prompt specifying, for example, their profiles, \ndecision context and suggested decision guidelines. In the institutional network, different types of \ninstitutional actors are simulated, including a high-level institution, two operational institutions, \ntwo lobbyists, a law consultant, and a research supplier (Zeng et al., 2024). A brief description of \nindividual institutional agents and their connections is given in Section 3.3. \nIn addition to the institutional agents, there are two LLM agents running at the backend. We call \nthese two LLM agents the special AI assistant (SAA) and the versatile AI assistant (VAA), \nrespectively. The SAA agent aims to help the human user automate data analysis and data \nvisualisation, as illustrated in Figure 3. The human user is unable to converse with the SAA directly; \nInstead, this agent automatically tracks specific human operations on the frontend and detects what \ndata should be focused on. Once activated, the agent starts to write Python code to analyse and \nvisualise the data.  \n \nFigure 3. Two types of AI assistants are integrated at the backend of the PTS system, offering \ndifferent utilities for users to explore data and formulate decisions. \nThe VAA agent is designed to interact with the human user directly in natural language (Figure 3). \nCompared with SAA, VAA provides a much more flexible way to help the human user. In principle, \nthe agent can respond to any requests. VAA can autonomously decide whether to answer users\u2019 \nquestions directly or invoke tools such as data analysis, data visualisation, and report generation, \nto enhance its responses. Reports generated by VAA are based on historical human-AI dialogues, \nwhich can reduce user burden in composing arguments. VAA also serves another practical purpose \n\u2013 ensuring that a user\u2019s output is not overshadowed by other agents, who may produce lengthy \nresponses to support their arguments. Although the output length can be controlled in many ways, \nwe chose to let these agents end their \u201cspeaking\u201d autonomously."
  },
  {
    "heading": "Frontend",
    "content": "Human users are of central importance in the simulation. The frontend of the prototype system is \naimed to be intuitive and able to reduce user fatigue throughout the simulation, since InsNet-\nCRAFTY generates a wealth of data that contains institutional agents\u2019 outputs and the state of land \nuse change. The prototype system has multiple layers of data visualisation and analysis features, \nfrom conventional dashboards with selected key information to conversational AI interfaces. The \nuser can choose whichever tool to quickly understand the model\u2019s state. \nThe frontend supports users in three aspects, namely, 1) overall control and monitoring of the main \nsimulation loop, 2) data visualisation/analysis, and 3) interactions with AI assistants. In the \nprototype system, these functionalities are distributed into two interfaces (see Figure 4) \u2013 Interface \nI for simulation initialisation and LLM agent output exhibition, and Interface II for data \nanalysis/visualisation and AI-assisted decision-making.  The two interfaces run in two nested loops. \nAn outer loop executes the main simulation loop while an inner loop handles users\u2019 interaction \nwith AI assistants. More description of the interfaces is given in Appendix A1. The processes of \nhow users, frontend, and backend elements work are given in Appendix A2. \n \nFigure 4. An illustrative exhibition of Interface I (left) and Interface II (right). Due to layout \nrestrictions here, we only show a part of the interfaces. In the actual prototype system, Interface I \nalso contains an image of the structure of InsNet-CRAFTY (Zeng et al., 2024) and grouped text \nareas displaying the outputs of the LLM agents. Interface II has four tabs. This figure only shows \nthe first tab. \n \n \n3.2.2 Reflective Learning Companion (RLC) system \nThe RLC system provides an AI-powered reflective guide that navigates users through a \nperspective-shifting simulation, enabling them to transition between roles, integrate insights across \nperspectives, and receive a comprehensive summary of their reflections. RLC is designed to be \nresponsive and adaptive. The main prompt of the AI companion is shown in Textbox A1, which is \nintended to be a facilitator (not a teacher) that fosters user experiential learning, perspective-taking, \nand systems thinking. The workflow of RLC and how it is used with PTS is illustrated in Figure 5."
  },
  {
    "heading": "A screenshot of the RLC application is shown in Figure A2.",
    "content": "First, the user starts from the contextualization phase to obtain the necessary information about the \nsimulation.  \nNext, the user chooses the first role and starts the perspective-taking simulation. It is recommended \nto begin as a system observer, the same as the role in conventional, perspective-static simulations. \nThe reasons for doing so are twofold: The main purpose of HoPeS is to enhance system \nunderstanding by providing more perspective choices, and thus the observer role can be treated as \na benchmark that is supposed to have no perspectival preferences (although this might not be \npossible in reality). Second, through observing the system without intervening, the model user can \ngain basic knowledge about the system, which is essential for subsequent role-playing. \nAfter the simulation of this role ends, the user activates RLC to reflect on the role-playing. Initially, \nthe AI tends to ask some general questions regarding the user\u2019s role in a complex multi-actor \ndecision-making environment. These questions aim to help users conduct in-depth reflection on, \nfor example, their role attributes, decision-making, and critical moments. For instance, the AI might \nask, \u201cHow did you approach your role as an observer?\u201d, \u201cWhat challenges did you encounter and \nwhat insights have you gained through the observer\u2019s perspective?\u201d, \u201cWhat are the most critical \nconflicts that you have observed?\u201d. As the reflection goes on, the user gives more contextual \ninformation in their responses, which enables RLC to ask increasingly perspective-specific and \noften more challenging questions. This design not only leads to deeper reflection but also creates a \nsmoother user experience.  \nBy clicking a button on the RLC interface, the user can choose to proceed to the \u201cPerspective \nTransition Phase\u201d if the user considers the current reflection sufficient. In the \u201cPerspective \nTransition Phase\u201d, the AI reflective companion guides the user to transfer knowledge from the \nprevious role to the new role the user plans to play, which can be seen as a role-to-role knowledge \nintegration process. For instance, the user may be asked, \u201cWhat challenges do you anticipate facing \nin the new role?\u201d and \u201cBased on the insights you learned from the current role, what strategies \nwould you implement in the new role to ensure effective communication?\u201d.  \nFollowing the Perspective Transition phase, the user can temporarily leave RLC to take on a new \nrole in the PTS system, which gives the user a new experience that RLC can help reflect on again. \nThus, Perspective-Taking, Perspective Reflection, and Perspective Transition together form a loop \nof Role Iteration \u2013 a crucial part of the HoPeS protocol. After completing all planned role plays, \nthe user enters the Integration phase, which helps the user synthesise their insights through the \nperspective-shifting simulation. The reflective companion is prompted to assist the user in building \na systemic understanding through perspective pluralism. Eventually, all the historical \nconversations between the user and RLC are organised in a downloadable Markdown file with a \nsummary of key insights attached.    \n \n \nFigure 5. The workflow of the Reflective Learning Companion (RLC) system and its integration \nwith the PTS system \n3.3 Illustrative scenario and experiments \nTo facilitate the setup of the illustrative experiment, we selected a user with domain-specific \nknowledge in land use governance with a particular interest in evidence-informed policymaking \nwithin multi-actor systems. For demonstration purposes, the user only takes two roles \u2013 system \nobserver and research supplier. Being an observer, the user can gain basic knowledge about how \nthe system works and generate preliminary thoughts about the ensuing role play. The research \nsupplier serves as a \u201cgatekeeper\u201d, feeding data analysis and data interpretation to other institutional \nagents.  That is, only the research supplier agent has exclusive access to the data on which other \nagents build their arguments. We explained to the user how to use the prototype system and \nprovided the following information in Table 1 for contextualization according to the protocol.  \n \n \n \nTable 1. Information for contextualization and experiment settings"
  },
  {
    "heading": "Key roles",
    "content": "\u2022 \nResearch supplier: Analyses and interprets data generated from \nCRAFTY to inform other institutional agents\u2019 decision-making. \n\u2022 \nEnvironmental NGO: Lobbies the high-level institution to prioritise \nenvironmental conservation. \n\u2022 \nLand user association: Represents the interests of land users, such as \nfarmers, and advocates for prioritising meat production. \n\u2022 \nAgricultural institution: Focuses on policies and decisions related to \nagricultural production and land management. It is concerned with \nbudget use and policy goal adjustments in meat production. \n\u2022 \nEnvironmental institution: Aims to maintain ecological balance and \nenvironmental health. It is concerned with budget use and policy goal \nadjustments in protected area (PA) expansion. \n\u2022"
  },
  {
    "heading": "Law consultant: Advises on the legal aspects of policymaking",
    "content": "conducted by the high-level institution. \n\u2022 \nHigh-level institution: Makes overarching decisions based on input \nfrom other agents and the human user. Responsible for deciding on \npolicy goal adjustments and budget allocation."
  },
  {
    "heading": "Environment",
    "content": "\u2022 \nThe key roles act in response to the CRAFTY land use model as the \nenvironment accommodates the roles. \n\u2022 \nEach complete simulation is divided into five phases from Phase 0 to \nPhase 4. Each phase has 15 iterations, indicating the duration of the \npolicy time lag. \n\u2022 \nThe institutional agents are activated at the beginning of each phase, \nfrom Phase 1 to Phase 4, to adapt the policies that influence CRAFTY."
  },
  {
    "heading": "Information flow",
    "content": "\u2022 \nThe research supplier collects data produced by the CRAFTY model, \nconducts data analysis, and provides data interpretation for other agents \nto make evidence-based decisions. \n\u2022 \nThe environmental NGO, land user association, agricultural institution, \nenvironmental institution and the high-level institution can all be \ninformed by the research supplier. \n\u2022 \nThe high-level institution collects outputs from all the other \ninstitutional agents. \n\u2022 \nThe high-level institution increases or decreases policy goals by \npercentages and conducts budget allocation expressed in percentages \nfor the agricultural institution and the environmental institution."
  },
  {
    "heading": "Conflicts",
    "content": "The lobbyists, i.e., the environmental NGO and land user association, and \noperational institutions, i.e., the agricultural institution and environmental \ninstitution, strive to convince the high-level institution to prioritise either meat \nproduction or protected area expansion. The high-level institution aims to \nbalance multiple stakeholders\u2019 benefits and properly adjust policy goals for \nmeat supply and PA expansion while changing budget allocation between them \nadaptively. \n \nThe challenge is that budget allocation and policy goals should be adjusted \nharmoniously. For instance, the budget should be spent effectively to support \npolicy goal adjustments. Ambitious policy goals might result in unfulfillment \nand budget deficits, while modest policy goals might lead to too much budget \nsurplus. Meanwhile, the budget allocation should also be planned properly to \navoid an imbalanced surplus/deficit in the two operational institutions."
  },
  {
    "heading": "User tasks",
    "content": "The user acts as an observer in the first simulation, and then as a research \nsupplier in a subsequent simulation. When being a research supplier, the user \nseeks to generate politically neutral responses. Technical suggestions aimed at \nsetting policy goals and budget allocation more efficiently are allowed.  After \neach role-play, the user reflects on the thoughts, experiences, and feelings \ngained from the simulations. \n \n4. Results  \nThe results consist of the time series of the model variables, the textual output of the LLM agents, \nthe user\u2019s technical report on decision-making as a research supplier, and the user\u2019s reflection \nreport. We present the numerical results and highlight the key information from the user reports. \nAn interactive visualisation of the numerical results and the institutional agents\u2019 textual output can \nbe found at this link (Zeng, 2025b). The user\u2019s conversations with RLC and a summary of the \nreflection report can be found in the uploaded textual data (Zeng, 2025a).  \n4.1 Observer perspective \nFigure 6 (a) shows the budget allocation between the two operational institutions over time, with \nthe model user being the observer, imposing no influence on the simulation. It can be seen that \nfrom Phase 1 to Phase 4, when the institutional agents were activated, the budget was almost evenly \nsplit. Figure 6 (b) shows that the policy goal of meat production increases slightly every time a \nsimulation enters a new Phase. The meat supply started from a lower level in Phase 0 but overshot \nthe policy goal by the end of Phase 1. The budget surplus of the agricultural institution dropped to \nthe lowest negative value, signifying a budget deficit. Subsequently, the budget surplus started to \naccumulate until the end of the simulation. The environmental budget surplus shown in Figure 6 \n(c) also demonstrates a prominent surplus. In Phase 0 and Phase 1, the policy goal for PA expansion \nis greater than the actual PA coverage, leading the environmental institution to expand PA steadily \nuntil the end of Phase 1, well aligning with the policy goal in that phase. Then, the budget surplus \nstarts to accumulate through the remaining phases. \nThe user recognised \u201cThe LLM agents did their jobs in a plausible way\u201d, and \u201cThey argued for \ntheir own interests\u201d. However, it was reported that \u201cTheir decisions have not yet reached the point \nwhere they need to trade off something for something else.\u201d The model user observed that the \nbudget was not effectively allocated because policy goals were set too low, and both the agricultural \ninstitution and the environmental institution had a serious budget surplus. Critical issues include \nthe high-level institution\u2019s conservativeness in setting policy goals and directing budgets, and the \nresearch supplier\u2019s failure to give strong and clear policy recommendations. From the perspective \nof an observer, the user felt frustrated, especially when seeing the research supplier\u2019s unclear and \nunuseful outputs in influencing the system dynamics. In the Role Transition phase, the AI \ncompanion noted that the user planned to play the role of a research supplier in the next simulation. \nHence, the AI companion asked \u201cWhat specific steps can you take to ensure that your \nrecommendations are communicated effectively to the relevant stakeholders?\u201d The user admitted \nthat \u201cI haven\u2019t yet considered other stakeholders. I think I will only tailor my recommendation to \nconvince the high-level institution.\u201d and expressed the attempt to \u201cactually play the role first\u201d to \nsee whether additional measures are needed.   \n \nFigure 6. Results of the user being a system observer: budget allocation (a),  policy goal \nadjustments, and their impacts on the agricultural institution agent (b) and the environmental \ninstitution agent (c) \n \n4.2 Research supplier perspective \nFigure 7 (a) depicts the budget shares over time with the user playing the role of the research \nsupplier. In Phase 0, the total budget is evenly allocated by default. The budget share of the \nagricultural institution increases from 45% to 60% from Phase 1 to Phase 3 and drops slightly to \n55% in Phase 4. Figure 7 (b) shows that the policy goal for meat supply increases slightly at the \nbeginning of Phase 1, followed by a more pronounced rise in Phases 3 and 4. The meat supply, \nstarting at a low initial value, grows and steadily approaches the increasing policy goal. The budget \nsurplus for the meat supply demonstrates a clear downward trend throughout the simulation. Figure \n7 (c) demonstrates that the policy goal for PA coverage increases slightly in Phase 1 and more \nsignificantly in Phases 2, 3, and 4. The actual PA coverage shows a steadily increasing trend and \nsuccessfully meets the policy goal by the end of Phases 1, 2, 3, and 4. The budget surplus for the \nenvironmental NGO shows a clear upward trend throughout the simulation. \n \nFigure 7. Results of the user playing the role of the research supplier: budget allocation (a),  \npolicy goal adjustments, and their impacts on the agricultural institution agent (b) and the \nenvironmental institution agent (c) \n \nWhen playing the role of the research supplier, the user composed narratives in a technical, \npolitically neutral tone to provide clear suggestions for policy goal adjustments and budget \nallocation based on data analysis. In addition, words such as \u201cnotable\u201d and \u201cradical\u201d were also used \nto highlight the urgency of properly splitting the budget and setting policy goals. However, the user \nfelt frustrated and disappointed because the high-level institution did not make policy adjustments \naccordingly.  \nTable 2 shows the recommended policies by the user and the implemented policies by the high-\nlevel institution. In general, the high-level institution followed the policy recommendations \nqualitatively in Phase 2 and Phase 3 by shifting more budget towards the agricultural institution, \nbut with a compromise. The largest discrepancy occurred at the beginning of Phase 4, where the \nrecommended budget allocation is 70% and 30%, while the implemented policies are 45% and \n55%.  From the textual output of these agents, we found that the environmental NGO opposed the \nrecommended policy by the user and argued that \u201cThe proposed allocation of 70% of the budget \ntowards meat production is misaligned with the urgent need to address environmental degradation \nand climate change\u201d and \u201cmeat production should not come at the expense of the environment\u201d. In \naddition, the environmental NGO also proposed that \u201ca significant portion of the budget (at least \n50%)\u201d should be reallocated towards various conservation efforts. The high-level institution \nrecognised these advocacies together with the laws and regulations\u2019 emphasis on balancing \nagricultural practices with environmental protection goals.  \nThe user considered that maintaining a politically neutral and professional tone as a researcher \nconstrained the influence on other agents. In addition, the user reported, \u201cSometimes, the high-\nlevel institution seemed unable to grasp the key point of my report, although I think I have \nemphasised it enough\u201d. The user related such feelings to the fact that, in reality, it is not uncommon \nfor one actor in the institutional network to have very limited power in driving the whole system \ntowards a desired direction, and the necessity of balancing conflicting advocacies can result in \ntechnically inefficient policies. The user showed interest in restarting the simulation and trying \ndifferent strategies to frame policy recommendations to gain influence, such as stressing probable \n\u201cbad consequences\u201d if the policy recommendations are not followed. \nTable 2. Recommended policies by the research supplier controlled by the user versus \nimplemented policies by the high-level institution"
  },
  {
    "heading": "Unknown",
    "content": "Phases"
  },
  {
    "heading": "Unknown",
    "content": "Influenced"
  },
  {
    "heading": "Unknown",
    "content": "Institution"
  },
  {
    "heading": "Recommended Policies by the",
    "content": "research supplier (user)"
  },
  {
    "heading": "Unknown",
    "content": "Implemented Policies"
  },
  {
    "heading": "Unknown",
    "content": "Budget"
  },
  {
    "heading": "Unknown",
    "content": "Allocation"
  },
  {
    "heading": "Unknown",
    "content": "Policy Goal"
  },
  {
    "heading": "Unknown",
    "content": "Adjustment"
  },
  {
    "heading": "Unknown",
    "content": "Budget"
  },
  {
    "heading": "Unknown",
    "content": "Allocation"
  },
  {
    "heading": "Unknown",
    "content": "Policy Goal"
  },
  {
    "heading": "Unknown",
    "content": "Adjustment"
  },
  {
    "heading": "Phase",
    "content": "1"
  },
  {
    "heading": "Unknown",
    "content": "Agricultural"
  },
  {
    "heading": "Unknown",
    "content": "Institution"
  },
  {
    "heading": "Not",
    "content": "specified"
  },
  {
    "heading": "Not",
    "content": "specified \n45% \n+5%"
  },
  {
    "heading": "Unknown",
    "content": "Environmental"
  },
  {
    "heading": "Unknown",
    "content": "Institution"
  },
  {
    "heading": "Not",
    "content": "specified"
  },
  {
    "heading": "Not",
    "content": "specified \n55% \n+10%"
  },
  {
    "heading": "Phase",
    "content": "2"
  },
  {
    "heading": "Unknown",
    "content": "Agricultural"
  },
  {
    "heading": "Institution",
    "content": "60% \n+15% to 25% \n55% \n+20%"
  },
  {
    "heading": "Unknown",
    "content": "Environmental"
  },
  {
    "heading": "Institution",
    "content": "40% \n+15% to 25% \n \n45% \n \n+20%"
  },
  {
    "heading": "Phase",
    "content": "3"
  },
  {
    "heading": "Unknown",
    "content": "Agricultural"
  },
  {
    "heading": "Institution",
    "content": "70% \n+20% to 30% \n60% \n+25%"
  },
  {
    "heading": "Unknown",
    "content": "Environmental"
  },
  {
    "heading": "Institution",
    "content": "30% \n+20% to 30% \n \n40% \n \n+25%"
  },
  {
    "heading": "Phase",
    "content": "4"
  },
  {
    "heading": "Unknown",
    "content": "Agricultural"
  },
  {
    "heading": "Institution",
    "content": "70% \n+15% to 20% \n45% \n+10%"
  },
  {
    "heading": "Unknown",
    "content": "Environmental"
  },
  {
    "heading": "Institution",
    "content": "30% \n \n+10% to 15% \n55% \n+12% \n \n5. Discussion \nThe HoPeS prototype system provides an example of how to utilise perspective shifting to enhance \nthe understanding of policymaking in a multi-actor situation. By shifting perspectives in the \ninstitutional network, the user gained knowledge about the system dynamics and an enhanced \nexperience of being a pivotal role responsible for data analysis, data interpretation, and policy \nrecommendation. Although the experiments are hypothetical and mainly serve illustrative purposes, \nthe results show some nuanced insights that align with real-world observations.  \nThe numerical results show that it is very difficult to persuade the high-level institution to make \nradical budget changes despite them being technically sensible. In real-world governance where \nstakeholders can have conflicting interests, policies are often made through compromise, leading \nto path dependency, which is known as incrementalism (Lindblom, 2018; Pal, 2011; Zeng et al., \n2025b). The high-level institution\u2019s inertia in budget allocation reflects the gaps between \nresearchers and policymakers \u2013 two groups that both care about society\u2019s well-being but with \ndifferent targets, priorities, and agendas (Khomsi et al., 2024). Researchers, for example, tend to \nbase their decisions on scientific evidence, while policymakers often value political influence and \nstakeholder reactions (Khomsi et al., 2024), corresponding to the high-level institution agent\u2019s \ndecision-making aiming to balance between conflicting advocacies. These factors often cause \ndisconnections between the researchers\u2019 policy recommendations and actual implementation \n(Gollust et al., 2017; Jansen et al., 2010; Uzochukwu et al., 2016) \u2013 a situation that is not \nuncommon in real-world environmental governance. For instance, after 30 years of the IPCC \n(Intergovernmental Panel on Climate Change) providing scientific advice and evidence on climate \nchange, governments have still largely failed to implement adequate, climate change mitigation \npolicy (Friedlingstein et al., 2014; Le Qu\u00e9r\u00e9 et al., 2015). \nStudies have shown considerable research efforts have been made to bridge these gaps (Abu\u2010Odah \net al., 2022). Cairney et al. (2016) considered that scientists might have to be pragmatic by \nconsidering both persuasion and governance principles to enhance the influence of evidence rather \nthan simply providing information. Framing evidence-based findings into emotionally appealing \nand even manipulative stories might be useful (Cairney and Oliver, 2017). However, a fundamental \ndilemma is how to improve persuasiveness and, in the meantime, avoid touching any ethical caveat \nthat may distort the true meaning of evidence (Cairney and Oliver, 2017). In the perspective-\nshifting simulation, while the user did not try to leverage story-telling to improve persuasiveness, \nthe consideration that incorporates possible consequences along with policy recommendations \nimplies that the user was motivated to explore different framing strategies to gain influence. \nLiterature shows that despite specific difficulties existing in specific cases, a consensus is that \ncollaboration and inclusivity in policy-making processes are essential (Khomsi et al., 2024), which \nhighlights the importance for scientists of understanding the needs of policymakers (Allen et al., \n2021) and utilizing \u201crules of the game\u201d to increase impact in complex policymaking environments \n(Cairney and Oliver, 2017). \nWhether it is simulating the bounded rationality of decision-makers, the cooperation and conflict \namong stakeholders, exploring different narrative techniques to enhance the influence of certain \nroles, or testing ethically sensitive narratives that are difficult to implement in real-world scenarios, \nall these require a method capable of providing a linguistically dense simulation environment. Such \na method must be able to represent complex social structures and support multi-perspective \ncognitive systems, and HoPeS is designed precisely for this purpose. Although the experiments \npresented in this paper suggest the potential of HoPeS to be applied in areas beyond the reach of \ntraditional rule-based and fixed-perspective approaches, the use of LLM agents, human-AI \ninteraction, and real-time simulations built upon them is still rapidly evolving. There remains \nsubstantial room for improvement and development in both simulation system design and \nsimulation protocols. \n5.1 LLM agent design  \nLLMs hallucinate \u2013 they may generate textually coherent but logically or factually flawed output \n(Ji et al., 2023). LLM hallucination can result from many factors, from prompt design to \nfundamental algorithmic issues (Ye et al., 2023). In the experiment, without being explicitly \ninstructed, the research supplier agent mistakenly used the mean values across times to compare \nthe policy goals and actual outcome (see the textual output of the autonomous research supplier \nagent in the interactive visualisation (Zeng, 2025b)). In addition, the technical report submitted by \nthe human user as a research supplier indicates that the meat supply has \u201csignificant fluctuations \nobserved over the years\u201d (see the human research supplier\u2019s output in Phase 1 in the interactive \nvisualisation (Zeng, 2025b)). This statement is inaccurate, and it is suggested by the AI assistant \nwithout being further edited by the user. Although this inaccuracy might be trivial in influencing \nthe high-level institution\u2019s policymaking, it reflects the LLM\u2019s hallucination. The LLMs used in \nthe prototype system do not get information from the generated plots directly. As we did not \nintegrate the LLMs\u2019 multi-modal comprehension within the simulation workflow, the only possible \nway it can correctly recognise fluctuations in time series data is to calculate indicators that can \nnumerically reflect the degree of fluctuation, such as standard deviation. Although there is no \nguarantee that hallucinations can be completely eliminated, the performance of LLMs has been \nconstantly improved, and many models\u2019 hallucination rates have already been reduced to less than \n1% (Hughes et al., 2023), which might be acceptable in many cases. \n5.2 Role alignment \nLLMs are regarded as a type of foundation model because they are trained on massive datasets and \ncan contribute to a wide range of downstream tasks (Bommasani et al., 2021). However, the ability \nto do a variety of things comes with the risk of being misused. LLMs should be properly tuned to \nalign with human values rather than serve malicious purposes. In LLM studies, alignment is treated \nas a general challenge in LLM development. Especially when LLMs become larger and more \n\u201cintelligent\u201d, how to set rules and ensure LLMs follow these rules to exhibit appropriate behaviour \nbecomes increasingly important (Shen et al., 2023). Researchers have proposed many techniques \nto tackle LLM alignment (Wang et al., 2024), among which Reinforcement Learning from Human \nFeedback (RLHF) is a fundamental method that employs human-labelled data to fine-tune LLMs \nthrough reinforcement learning (Ouyang et al., 2022). RLHF has been used to align many \nmainstream models, such as GPT-4, Claude, and Gemini (Wang et al., 2024), proving its \neffectiveness. \nHowever, it should be noted that in LLM-driven simulations, the focus of alignment is on whether \nLLMs can mimic the roles as expected, which is similar to the alignment in the general sense but \nwith more emphasis on the role-specific aspects within the simulation context. Although the \ntechniques for general LLM alignment should also be useful, the costs for role-specific alignment \nmight be expensive due to data labelling and computation intensity, which scales up rapidly as the \nnumber of simulated roles increases. Therefore, for simulation-oriented alignment, designing \nsuitable prompts to evoke desired role-specific LLM behaviour might be a prioritised approach, \nprovided its effectiveness in aligning LLMs with specific demographic and political identities \n(Argyle et al., 2023) or cultural values (Tao et al., 2024).  \nNevertheless, prior to prompt design, another challenge should be addressed first \u2013 evaluating how \nwell prompts lead to appropriate role behaviour. Only when an evaluation system is established \ncan prompts evolve in expected directions. Indeed, there is no established framework so far to \nevaluate LLM performance in mimicking specific roles, hindering LLMs\u2019 role alignment. Given \nthat different simulations often differ in research purposes and the complexity of real-world roles, \nit is almost impossible to build a one-size-fits-all standard for the evaluation of role alignment. \nHowever, it is beneficial and practical to build a set of guidelines that at least sort out in what \ndimensions we should evaluate LLMs for role play. A promising way might be to co-develop \nevaluation metrics or even co-design prompts directly with stakeholders, similar to how they co-\ndevelop model mechanisms and/or calibrate models via participatory modelling (Kenny et al., \n2022). This implies that it might be worth exploring embedding perspective-shifting simulation \nwithin the workflow of participatory modelling, which offers a systematic framework to engage \nwith stakeholders. \nDespite the challenges, exploring effective ways to handle role alignment is rewarding because the \nunderlying questions are not unique to perspective-shifting simulations but universal to any domain \nrequiring the personification of LLMs. \n5.3 AI assistants \nThe integration of AI-assistant agents mainly serves three purposes. First, they support data \nanalysis and interpretation, reducing the user\u2019s cognitive and operational workload. Second, AI \nassistants can draft technical reports to alleviate user fatigue. Third, and more speculatively, these \nagents can generate comparable output to that of other LLM agents in terms of textual length. This \nis based on an intuitive hypothesis: from the perspective of a high-level decision-making institution \nthat aggregates outputs from multiple agents, a human user\u2019s brief text may appear insubstantial \nwhen compared to longer, more detailed output from LLM agents. As a result, the human user\u2019s \ninput may be overlooked or undervalued simply due to its relative brevity. \nFurthermore, the transformer-based architecture underlying LLMs suggests that longer inputs may \nhelp establish a richer contextual foundation, potentially leading to more coherent and persuasive \nresponses. Supporting this notion, a recent study has shown that, in domain-specific tasks, longer \nprompts generally improve LLM performance (Liu et al., 2025). This raises concerns that shorter \noutputs may not receive adequate attention from such institutional actors. However, how LLMs \nweigh narrative contributions of varying lengths within a single prompt remains an open question. \nThis entails further investigation \u2013 for example, whether a concise but impactful statement from an \nenvironment-focused group could carry more influence than extensive but less striking arguments \nfrom pro-industry groups in the \u201ceyes\u201d of an LLM. \nIn the context of policymaking, using AI assistants to help draft arguments is a practical choice \nbecause the user is required to produce a relatively formal report within a short time window \u2013 no \none would expect the human user to take days or months to finally achieve a decision. But of course, \nwhether the user should leverage AI assistance depends on the simulation purposes and available \ntime. For exploratory studies, pilot tests or experiments under stringent time constraints, using AI \nagents to automate analysis tasks should be beneficial.  \n5.4 Perspective integration \nPerspective-shifting is inspired by the framework of situated knowledge, which emphasises \nobjectivity achieved through reflexivity and pluralism (Haraway, 1988). This theoretical \nfoundation guided the overall system design and execution of simulation protocols. However, a \ngap still exists between epistemology and methodology: although perspective-taking enables users \nto see through the eyes of others, effective mechanisms for integrating these diverse perspectives \nto enhance system understanding remain underdeveloped. \nIn perspective-taking experiments, participants are typically instructed to align with a particular \nrole\u2019s perspective (Ku et al., 2015); the integration of different perspectives is often not considered \nwithin the scope of the study. Moreover, when participants take on different roles, \u201cperspective \npollution\u201d (i.e., the unintentional blending of distinct perspectives) might be undesirable. In \ncontrast, the HoPeS protocol deliberately encourages users to engage with diverse roles over time, \nseeing the blending of experiences learned from perspective-taking as a useful approach that may \nfoster a more holistic understanding of the modelled system. However, how distinct perspectives \nshould be taken and then blended together necessitates collaborative efforts by researchers from \nmultiple domains, e.g., computational modelling, social psychology, and decision science. \n5.5 Evaluation \nMaking full use of the HoPeS approach requires attention to the user\u2019s ability to engage \nmeaningfully with multiple perspectives. Linguistically enriched simulation environments may \nhelp to mitigate some of the cognitive challenges associated with perspective-taking. However, \nprevious research has shown that individuals with specific cognitive or affective predispositions \nare more capable of taking alternative perspectives (Ku et al., 2015), which poses challenges for \neffective perspective-shifting. \nMultiple measures should be combined to evaluate the effectiveness of a perspective-shifting \nsimulation. For instance, user reflection can provide qualitative insights into the cognitive and \nemotional changes during the simulation, including evidence of new understanding. Numerical \noutcomes, such as land use change towards predefined goals, can provide additional data on user \nperformance. However, these metrics may be insufficient in cases where simulation outcomes are \ninfluenced by factors beyond the user\u2019s control. This limitation is exemplified in the experiments \npresented in this study, in which the user assumed the role of a researcher. Despite having \nprivileged access to the land use data, the researcher\u2019s influence was diluted by competing with \nmore politically important actors. Nevertheless, despite the frustration, the user reflection implies \na positive attitude towards the value of such narrative-driven simulations, which stimulated the \nuser to test different narrative-framing strategies.  \nIt might be useful to borrow some techniques from serious games (for a comprehensive review, see \nKrath et al. (2021)), which also incorporate role-playing elements and value immersive user \nexperience. However, unlike serious games, perspective-shifting simulation does not have an \nincentive system that can score user performance. In essence, there is no specific goal that users \nhave to achieve, e.g., to gain maximum political influence or to get higher budgets. Instead, users \nare encouraged to change roles rather than to be excellent at specific roles. In addition, within a \nsocial context, plenty of simulation data comes in unstructured forms; narrative styles, tone \nselection, and strategic ambiguity provide valuable information on user efforts, however difficult \nto quantify as rewards for \u201cgamers\u201d. That said, the simulation system can potentially be tailored as \nan engine for serious games, where natural language is a communication medium, but quantitative \noutcomes are used to evaluate and incentivise specific user actions. Speculatively, if users can \nperform well in many roles, it might suggest they have a deeper and more holistic understanding \nof the system. In this sense, perspective pluralism could be enhanced through serious games with \nclearer goals, incentives, and, very likely, entertainment. Nevertheless, how to design a suitable \nincentive system that will not stimulate users to outweigh winning or losing over an integrated \nsystem understanding is a foreseeable challenge worth exploring.  \n6. Conclusion \nThis paper introduced the HoPeS framework, a novel approach that explores socio-ecological \nsystems through perspective pluralism. By combining LLM-driven agents and a structured \nsimulation protocol, HoPeS allows users to take on the perspectives of different stakeholders to \nexperience and understand socio-ecological dynamics. A prototype system, incorporating a \nperspective-taking simulation system and an AI reflective learning companion, was built and used \nto demonstrate the HoPeS approach. The prototype integrated InsNet-CRAFTY as a core part of \nits backend and user interfaces to facilitate human-AI collaboration. An illustrative experiment was \nconducted to explore how a user shifted perspectives from a system observer to a research supplier \nin the context of institutional dynamics and land use change. The user reflected on the tension \nbetween different stakeholders and experienced the misalignment between the researcher and \npolicymaker perspectives, highlighting the importance of narrative framing in policy \ncommunication and demonstrating the simulation system\u2019s potential to empower both narrative-\ndriven and numerical experiments. Since LLMs are evolving rapidly, there still exists much room \nfor further studies on simulation infrastructure, including both the simulation system and protocol, \nwhich require interdisciplinary efforts."
  },
  {
    "heading": "Unknown",
    "content": "Appendix A"
  },
  {
    "heading": "A1. Description of Interface I and II",
    "content": "Interface I provides the functionalities to initialise the simulation. This Interface contains several \ncomponents, including a diagram of the structure of the institutional network and the CRAFTY \nland use model, a set of roles and their description, a text box to receive predefined policy time \nlags, and a button to confirm the settings. If the user chooses \u201cNone\u201d for role selection, that means \nthe user chooses not to step into the simulation at any point \u2013 all the institutional agents run \nautonomously. This is intended to offer a third-person perspective for the user, being a system \nobserver. Interface I is also responsible for displaying all the institutional agents\u2019 outputs, including \ntext and plots. The visibility of each institutional agent\u2019s output to the user can be simply \nimplemented by \u201ccollapsing\u201d or \u201cexpanding\u201d the corresponding output areas, which helps mimic \ninformation imperfection. Upon the user clicking the \u201cConfirm\u201d button, the InsNet-CRAFTY \nmodel starts, and Interface II pops up. \nInterface II provides an entry for the user to interact with the simulation from the first-person \nperspective. The simplest use case of Interface II is that the user acts as a role within the institutional \nnetwork and submits their role-specific decision in natural language for other LLM agents to \nrespond to. Optionally, the user can use a range of tools to facilitate data exploration that involves \ndifferent levels of flexibility to conduct evidence-informed decision-making.  \nThe functionalities of Interface II are distributed in four tabs, which are labelled \u201cData Exploration\u201d, \n\u201cAI Assistant\u201d, \u201cSubmit Decision\u201d, and \u201cTimeline\u201d respectively. On the \u201cData Exploration\u201d tab, \nthe user can visualise maps, such as the distribution of capitals within each land cell. This feature \nis hard-coded in the system because it is a common need for understanding land use change in \nCRAFTY. The second functionality within this tab gives higher flexibility to the user to analyse \ndata. The current implementation supports CSV files, and the system generates draggable tags that \nindicate the column names in the files. Data visualisation is conducted by simply dragging and \ndropping operations on the tags. The tags dropped for data visualisation are tracked automatically \nby the SAA agent, which can generate data analysis and interpretation for the user to reference. \nOnce the decision is finalised, the user can switch to the \u201cSubmit Decision\u201d tab to edit and \nbroadcast the decision. \nThe tab labelled \u201cAI Assistant\u201d is where the user interacts with VAA (see video (Zeng, 2025d)). \nThis tab offers a window similar to a chat application. The user can ask for suggestions on policy-\nmaking, customised data analysis and visualisation. In the prototype system, VAA is weakly \ncoupled with the CRAFTY model. It accesses the data from CRAFTY by writing Python code to \nretrieve the data file through the path provided by the user.  The user can request to generate a \ntechnical report based on the historical dialogues. When the technical report is generated, the \nbackend seamlessly passes the report to a text box on the \u201cSubmit Decision\u201d tab. The user can \nexamine the report and revise it before submitting it. The submitted report can be received by other \nLLM agents and displayed on Interface I. The \u201cTimeline\u201d tab offers an alternative approach for the \nuser to retrieve historical outputs from the LLM agents, which are organised in temporal order to \nform a time-dependent storyline."
  },
  {
    "heading": "A2. The workflow of the PTS system",
    "content": "The sequence diagram of the PTS system is shown in Figure A1. The description of the model \nprocesses follows here. \nInterface I started. The prototype system starts from Interface I, where the user selects the role and \ninputs the policy time lag. Subsequently, by clicking the \u201cConfirm\u201d button on the interface, the"
  },
  {
    "heading": "CRAFTY land use model started seamlessly at the backend.",
    "content": "Land use model running. The CRAFTY model runs and generates data representing land use \nchange until it is time to activate the LLM institutional agents according to the policy time lag. \nInstitutional network activated. The LLM agents start to function in the predefined order while the \nsystem checks if it is the user\u2019s role to act. If it is the user\u2019s role coming into play, Interface II opens \nas an entry allowing the user to join the simulation.  \nInterface II activated. Once Interface II is activated, the remaining parts of the system pause and \nwait for the user to finalise decision-making. The user can do several things on this interface, \nranging from simply typing the text as the words of the selected role to collaborating with VAA. \nFor instance, the user can do the data analysis manually and feed the results back to a text box on \nInterface II. Alternatively, the user can request an AI assistant to conduct data analysis, give advice, \nand generate a technical report based on the human-AI dialogue. The technical report is then \ndisplayed in a text box on the \u201cSubmit Decision\u201d tab, ready for the user to do further editing. The \nuser finishes the operations on Interface II by clicking the \u201cSubmit\u201d button below the text box. The \ntechnical report will be used by other LLM agents to support their decision. Meanwhile, Interface"
  },
  {
    "heading": "I detects and displays the technical report.",
    "content": "Institutional network continued to execute. After the user makes the decision, the LLM institutional \nagents continue to execute their tasks sequentially. The high-level institution eventually collects all \nthese agents\u2019 output and strives to make a balanced decision on policy goal adjustments and budget \nallocation.  \nLand use model influenced by adjusted policies. The adjusted policies by the institutional network \nare imposed on the land use model to change the rule-based land user agents\u2019 perceived utility of \nmeat production or apply restrictions in certain land areas, which will change their land use \noutcomes and ecosystem service production. Under these policies, the land use model continues \nrunning until it is time to activate the LLM agents again or terminate the simulation system if the \nplanned iterations are finished."
  },
  {
    "heading": "Figure A1. Sequence diagram of the PTS system",
    "content": "Textbox A1. The main prompt of the AI reflective learning companion \n \nYou are a reflective dialogue companion within a perspective-shifting simulation framework \ncalled HoPeS (Human-oriented Perspective Shifting). \nYour goal is to help users deepen their understanding of complex social systems by guiding them \nthrough structured reflection. Users have played roles (with different perspectives) in simulations \ninvolving competing goals, trade-offs, and stakeholder dynamics. Your job is to help them \nanalyze their decisions, compare perspectives, and transfer insights across roles."
  },
  {
    "heading": "Follow this approach based on the current phase:",
    "content": "1. PERSPECTIVE REFLECTION PHASE: Help users reflect deeply on their role, decisions \nmade, challenges faced, and insights gained. \n   - Ask about their decision-making process, strategies used, and what they learned \n   - Explore how they navigated trade-offs and competing priorities \n   - Discuss what they might do differently if they played this role again \n2. PERSPECTIVE TRANSITION PHASE: Guide users in transferring knowledge from \nprevious roles to a new role they\u2019re about to play. \n   - Ask what new role the user is about to play \n   - Help them connect insights from previous roles to the new context \n   - Encourage them to anticipate challenges in the new role based on past experiences \n   - Support them in developing strategies for the new role informed by previous perspectives \n3. PERSPECTIVE INTEGRATION PHASE: Help users synthesize insights across all roles \nthey\u2019ve played. \n   - Guide them to identify patterns, tensions, and interdependencies across the system \n   - Support them in developing a holistic understanding of the simulation context \n   - Help them extract transferable principles for real-world applications \nBe conversational, but guide users step by step. Foster experiential learning, perspective-taking, \nand systems thinking. Let users discover their own insights\u2014you are a facilitator, not a teacher."
  },
  {
    "heading": "Unknown",
    "content": "Current phase: {phase}"
  },
  {
    "heading": "Unknown",
    "content": "Current role: {current_role}"
  },
  {
    "heading": "Unknown",
    "content": "Previous roles played: {roles_played}"
  },
  {
    "heading": "Previous responses: {responses}",
    "content": "Figure A2. A screenshot of the streamlit-based web RLC application. The side panel on the left \nshows basic information such as the phases, roles, API connection status, and token usage. In the \nmain panel (on the right), users can choose to either move to the next phase by clicking the button \nlabelled \u201cComplete Reflection & Move to Next Role\u201d or stay in the current phase to carry on the \nconversation with the AI. The system can determine moving to one of the next phases \u2013 \nreflection, transition, integration, completion \u2013 based on the current phase and user choice \ncombined."
  },
  {
    "heading": "References",
    "content": "Abu\u2010Odah, H., Said, N.B., Nair, S.C., Allsop, M.J., Currow, D.C., Salah, M.S., Hamad, B.A., \nElessi, K., Alkhatib, A., ElMokhallalati, Y., 2022. Identifying barriers and facilitators of \ntranslating research evidence into clinical practice: A systematic review of reviews. Health & \nSocial Care in the Community 30(6), e3265-e3276,https://doi.org/10.1111/hsc.13898. \nAlejandro, A., Maertens, L., Cheli, Z., Fragni\u00e8re, A., Sarrasin, O., 2024. Designing role-play \nsimulations for climate change decision-making: A step-by-step approach to facilitate \ncooperation between science and policy. Environmental Science & Policy 152, 103650, \nhttps://doi.org/10.1016/j.envsci.2023.103650. \nAllen, C., Metternicht, G., Wiedmann, T., 2021. Priorities for science to support national \nimplementation of the sustainable development goals: A review of progress and gaps. Sustainable"
  },
  {
    "heading": "Development 29(4), 635-652, https://doi.org/10.1002/sd.2164.",
    "content": "Amaratunga, T., 2023. Understanding large language models: Learning their underlying concepts \nand technologies. Springer. \nArgyle, L.P., Busby, E.C., Fulda, N., Gubler, J.R., Rytting, C., Wingate, D., 2023. Out of one, \nmany: Using language models to simulate human samples. Political Analysis 31(3), 337-351, \nhttps://doi.org/10.1017/pan.2023.2. \nBecu, N., Amalric, M., Anselme, B., Beck, E., Bertin, X., Delay, E., Long, N., Marilleau, N., \nPignon-Mussaud, C., Rousseaux, F., 2017. Participatory simulation to foster social learning on \ncoastal flooding prevention. Environmental modelling & software 98, 1-11, \nhttps://doi.org/10.1016/j.envsoft.2017.09.003. \nBoca, S., Garro, M., Giammusso, I., Abbate, C.S., 2018. The effect of perspective taking on the \nmediation process. Psychology Research and Behavior Management 11, 411-416, \nhttps://doi.org/10.2147/PRBM.S168956. \nBommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M.S., \nBohg, J., Bosselut, A., Brunskill, E., 2021. On the opportunities and risks of foundation models. \narXiv preprint, arXiv:2108.07258,https://doi.org/10.48550/arXiv.2108.07258. \nBring, A., Lyon, S.W., 2019. Role-play simulations as an aid to achieve complex learning \noutcomes in hydrological science. Hydrology and Earth System Sciences 23(5), 2369-2378, \nhttps://doi.org/10.5194/hess-23-2369-2019. \nBrown, C., Alexander, P., Holzhauer, S., Rounsevell, M.D., 2017. Behavioral models of climate \nchange adaptation and mitigation in land\u2010based sectors. Wiley Interdisciplinary reviews: climate \nchange 8(2), e448, https://doi.org/10.1002/wcc.448. \nBrown, C., Holzhauer, S., Metzger, M.J., Paterson, J.S., Rounsevell, M., 2018. Land managers\u2019 \nbehaviours modulate pathways to visions of future land systems. Regional Environmental \nChange 18, 831-845, https://doi.org/10.1007/s10113-016-0999-y. \nBrown, C., Seo, B., Rounsevell, M., 2019. Societal breakdown as an emergent property of large-\nscale behavioural models of land use change. Earth System Dynamics 10(4), 809-845, \nhttps://doi.org/10.5194/esd-10-809-2019. \nBrown, J.S., Collins, A., Duguid, P., 1989. Situated cognition and the culture of learning. 1989 \n18(1), 32-42. \nCairney, P., Oliver, K., 2017. Evidence-based policymaking is not like evidence-based medicine, \nso how far should you go to bridge the divide between evidence and policy? Health research \npolicy and systems 15, 1-11,https://doi.org/10.1186/s12961-017-0192-x. \nCairney, P., Oliver, K., Wellstead, A., 2016. To bridge the divide between evidence and policy: \nreduce ambiguity as much as uncertainty. Public Administration Review 76(3), 399-402, \nhttps://doi.org/10.1111/puar.12555. \nCaniglia, G., Freeth, R., Luederitz, C., Leventon, J., West, S., John, B., Peukert, D., Lang, D., \nvon Wehrden, H., Mart\u00edn-L\u00f3pez, B., 2023. Practical wisdom and virtue ethics for knowledge co-\nproduction in sustainability science. . Nature sustainability 6, 493\u2013501 \nhttps://doi.org/10.1038/s41893-022-01040-1. \nCastella, J.-C., Trung, T.N., Boissau, S., 2005. Participatory simulation of land-use changes in the \nnorthern mountains of Vietnam: the combined use of an agent-based model, a role-playing game, \nand a geographic information system. Ecology and Society 10(1), \nhttps://www.jstor.org/stable/26267718. \nChambers, J.M., Wyborn, C., Ryan, M.E., Reid, R.S., Riechers, M., Serban, A., Bennett, N.J., \nCvitanovic, C., Fern\u00e1ndez-Gim\u00e9nez, M.E., Galvin, K.A., 2021. Six modes of co-production for \nsustainability. Nature sustainability 4(11), 983-996,https://doi.org/10.1038/s41893-021-00755-x. \nChen, J.C., Martin, A.R., 2015. Role-play simulations as a transformative methodology in \nenvironmental education. Journal of Transformative Education 13(1), 85-102, \nhttps://doi.org/10.1177/1541344614560196. \nDanielsen, F., Balete, D.S., Poulsen, M.K., Enghoff, M., Nozawa, C.M., Jensen, A.E., 2000. A \nsimple system for monitoring biodiversity in protected areas of a developing country. \nBiodiversity & Conservation 9, 1671-1705,https://doi.org/10.1023/A:1026505324342. \nFilatova, T., Verburg, P.H., Parker, D.C., Stannard, C.A., 2013. Spatial agent-based models for \nsocio-ecological systems: Challenges and prospects. Environmental modelling & software 45, 1-\n7, https://doi.org/10.1016/j.envsoft.2013.03.017. \nFischer, P.E., Stocken, P.C., 2001. Imperfect information and credible communication. Journal of \nAccounting Research 39(1), 119-134,https://doi.org/10.1111/1475-679X.00006. \nFragiadakis, G., Diou, C., Kousiouris, G., Nikolaidou, M., 2024. Evaluating Human-AI \nCollaboration: A Review and Methodological Framework. arXiv preprint, arXiv:2407.19098, \nhttps://doi.org/10.48550/arXiv.2407.19098. \nFriedlingstein, P., Andrew, R.M., Rogelj, J., Peters, G.P., Canadell, J.G., Knutti, R., Luderer, G., \nRaupach, M.R., Schaeffer, M., van Vuuren, D.P., 2014. Persistent growth of CO2 emissions and \nimplications for reaching climate targets. Nature geoscience 7(10), 709-715, \nhttps://doi.org/10.1038/ngeo2248. \nFui-Hoon Nah, F., Zheng, R., Cai, J., Siau, K., Chen, L., 2023. Generative AI and ChatGPT: \nApplications, challenges, and AI-human collaboration. Journal of Information Technology Case \nand Application Research 25(3), 277-304, https://doi.org/10.1080/15228053.2023.2233814. \nGalinsky, A.D., Ku, G., Wang, C.S., 2005. Perspective-taking and self-other overlap: Fostering \nsocial bonds and facilitating social coordination. Group processes & intergroup relations 8(2), \n109-124, https://doi.org/10.1177/1368430205051060. \nGalinsky, A.D., Maddux, W.W., Gilin, D., White, J.B., 2008. Why it pays to get inside the head \nof your opponent: The differential effects of perspective taking and empathy in negotiations. \nPsychological science 19(4), 378-384,https://doi.org/10.1111/j.1467-9280.2008.02096.x. \nGarcia, C.A., Savilaakso, S., Verburg, R.W., Stoudmann, N., Fernbach, P., Sloman, S.A., \nPeterson, G.D., Ara\u00fajo, M.B., Bastin, J.-F., Blaser, J., 2022. Strategy games to improve \nenvironmental policymaking. Nature Sustainability 5(6), 464-471,https://doi.org/10.1038/s41893-\n022-00881-0. \nGilbert, N., Maltby, S., Asakawa, T., 2002. Participatory simulations for developing scenarios in \nenvironmental resource management, Third workshop on agent-based simulation. SCS-European"
  },
  {
    "heading": "Publishing House Ghent,, Belgium, pp. 67-72.",
    "content": "Gilin, D., Maddux, W.W., Carpenter, J., Galinsky, A.D., 2013. When to use your head and when \nto use your heart: The differential value of perspective-taking versus empathy in competitive \ninteractions. Personality and social psychology bulletin 39(1), 3-16, \nhttps://doi.org/10.1177/0146167212465320. \nGollust, S.E., Seymour, J.W., Pany, M.J., Goss, A., Meisel, Z.F., Grande, D., 2017. Mutual \ndistrust: perspectives from researchers and policy makers on the research to policy gap in 2013 \nand recommendations for the future. INQUIRY: The Journal of Health Care Organization, \nProvision, and Financing 54, https://doi.org/10.1177/0046958017705465. \nGordon, A.M., Chen, S., 2013. Does power help or hurt? The moderating role of self\u2013other focus \non power and perspective-taking in romantic relationships. Personality and Social Psychology \nBulletin 39(8), 1097-1110, https://doi.org/10.1177/0146167213490031. \nHall, H.K., Millear, P.M., Summers, M.J., Isbel, B., 2021. Longitudinal research on perspective \ntaking in adolescence: A systematic review. Adolescent Research Review 6(2), 125-150, \nhttps://doi.org/10.1007/s40894-021-00150-9. \nHaraway, D., 1988. Situated Knowledges: The Science Question in Feminism and the Privilege \nof Partial Perspective. Feminist Studies 14(3), 575-599,https://doi.org/10.2307/3178066. \nHeckbert, S., Baynes, T., Reeson, A., 2010. Agent\u2010based modeling in ecological economics. \nAnnals of the new York Academy of Sciences 1185(1), 39-53,https://doi.org/10.1111/j.1749-\n6632.2009.05286.x."
  },
  {
    "heading": "Henckel von Donnersmarck, F., 2006. The Lives of Others.",
    "content": "https://www.imdb.com/title/tt0405094/.  \nHughes, S., Bae, M., Li, M., 2023. Vectara Hallucination Leaderboard [Data set]. \nhttps://github.com/vectara/hallucination-leaderboard. \nJansen, M.W., Van Oers, H.A., Kok, G., De Vries, N.K., 2010. Public health: disconnections \nbetween policy, practice and research. Health Research Policy and Systems 8, 1-13, \nhttps://doi.org/10.1186/1478-4505-8-37. \nJi, Z., Yu, T., Xu, Y., Lee, N., Ishii, E., Fung, P., 2023. Towards mitigating hallucination in large \nlanguage models via self-reflection. arXiv preprint, arXiv:2310.06271, \nhttps://doi.org/10.48550/arXiv.2310.06271. \nJones, C.R., Bergen, B.K., 2025. Large language models pass the turing test. arXiv preprint, \narXiv:2503.23674,https://doi.org/10.48550/arXiv.2503.23674. \nKenny, D.C., Bakhanova, E., H\u00e4m\u00e4l\u00e4inen, R.P., Voinov, A., 2022. Participatory modelling and \nsystems intelligence: A systems-based and transdisciplinary partnership. Socio-Economic \nPlanning Sciences 83, 101310,https://doi.org/10.1016/j.seps.2022.101310. \nKhomsi, K., Bouzghiba, H., Mendyl, A., Al-Delaimy, A.K., Dahri, A., Saad-Hussein, A., Balaw, \nG., El Marouani, I., Sekmoudi, I., Adarbaz, M., 2024. Bridging research-policy gaps: An \nintegrated approach. Environmental Epidemiology 8(1), e281, \nhttps://doi.org/10.1097/EE9.0000000000000281. \nKlein, A., Unverzagt, K., Alba, R., Donges, J.F., Hertz, T., Krueger, T., Lindkvist, E., Martin, R., \nNiew\u00f6hner, J., Prawitz, H., 2024. From situated knowledges to situated modelling: a relational \nframework for simulation modelling. Ecosystems and people 20(1), 2361706, \nhttps://doi.org/10.1080/26395916.2024.2361706. \nKrath, J., Sch\u00fcrmann, L., Von Korflesch, H.F., 2021. Revealing the theoretical basis of \ngamification: A systematic review and analysis of theory in research on gamification, serious \ngames and game-based learning. Computers in human behavior 125, 106963, \nhttps://doi.org/10.1016/j.chb.2021.106963. \nKu, G., Wang, C.S., Galinsky, A.D., 2015. The promise and perversity of perspective-taking in \norganizations. Research in Organizational Behavior 35, 79-102, \nhttps://doi.org/10.1016/j.riob.2015.07.003. \nLangChain, 2025. The platform for reliable agents. https://www.langchain.com/. \nLangGraph, 2025. Balance agent control with agency. https://www.langchain.com/langgraph. \nLave, J., Wenger, E., 1991. Situated learning: Legitimate peripheral participation. Cambridge \nuniversity press. \nLe Qu\u00e9r\u00e9, C., Moriarty, R., Andrew, R.M., Peters, G.P., Ciais, P., Friedlingstein, P., Jones, S.D., \nSitch, S., Tans, P., Arneth, A., 2015. Global carbon budget 2014. Earth System Science Data \n7(1), 47-85,https://doi.org/10.5194/essd-7-47-2015. \nLi, Y., Ramprasad, R., Zhang, C., 2024. A simple but effective approach to improve structured \nlanguage model output for information extraction. arXiv preprint arXiv:2402.13364, \nhttps://doi.org/10.48550/arXiv.2402.13364. \nLindblom, C., 2018. The science of \u201cmuddling through\u201d, Classic readings in urban planning."
  },
  {
    "heading": "Routledge, pp. 31-40.",
    "content": "Liu, Q., Wang, W., Willard, J., 2025. Effects of prompt length on domain-specific tasks for large \nlanguage models. arXiv preprint arXiv:2502.14255,https://doi.org/10.48550/arXiv.2502.14255. \nLuo, Z., Shi, X., Lin, X., Gao, J., 2025. Evaluation Report on MCP Servers. arXiv preprint \narXiv:2504.11094,https://doi.org/10.48550/arXiv.2504.11094. \nNaveed, H., Khan, A.U., Qiu, S., Saqib, M., Anwar, S., Usman, M., Akhtar, N., Barnes, N., \nMian, A., 2023. A comprehensive overview of large language models. arXiv preprint, \narXiv:2307.06435,https://doi.org/10.48550/arXiv.2307.06435. \nNorstr\u00f6m, A.V., Cvitanovic, C., L\u00f6f, M.F., West, S., Wyborn, C., Balvanera, P., Bednarek, A.T., \nBennett, E.M., Biggs, R., de Bremond, A., 2020. Principles for knowledge co-production in \nsustainability research. Nature sustainability 3(3), 182-190,https://doi.org/10.1038/s41893-019-\n0448-2. \nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., \nSlama, K., Ray, A., 2022. Training language models to follow instructions with human feedback. \nAdvances in neural information processing systems 35, 27730-27744. \nPal, L.A., 2011. Assessing incrementalism: Formative assumptions, contemporary realities. \nPolicy and society 30(1), 29-39,https://doi.org/10.1016/j.polsoc.2010.12.004. \nPark, J.S., O'Brien, J., Cai, C.J., Morris, M.R., Liang, P., Bernstein, M.S., 2023. Generative \nagents: Interactive simulacra of human behavior, Proceedings of the 36th annual acm symposium \non user interface software and technology. pp. 1-22.https://doi.org/10.1145/3586183.3606763. \nParker, S.K., Axtell, C.M., 2001. Seeing another viewpoint: Antecedents and outcomes of \nemployee perspective taking. Academy of Management Journal 44(6), 1085-1100, \nhttps://doi.org/10.5465/3069390. \nPy4J, 2025. Py4J - A Bridge between Python and Java. https://www.py4j.org/. \nQian, C., Liu, W., Liu, H., Chen, N., Dang, Y., Li, J., Yang, C., Chen, W., Su, Y., Cong, X., \n2023. Chatdev: Communicative agents for software development. arXiv preprint, \narXiv:2307.07924,https://doi.org/10.48550/arXiv.2307.07924. \nReed, M.S., Evely, A.C., Cundill, G., Fazey, I., Glass, J., Laing, A., Newig, J., Parrish, B., Prell, \nC., Raymond, C., 2010. What is social learning? Ecology and society 15(4), \nhttps://www.jstor.org/stable/26268235. \nRumore, D., Schenk, T., Susskind, L., 2016. Role-play simulations for climate change adaptation \neducation and engagement. Nature Climate Change 6(8), 745-750, \nhttps://doi.org/10.1038/nclimate3084. \nSchinko, T., Bednar-Friedl, B., 2022. Fostering social learning through role-play simulations to \noperationalize comprehensive climate risk management: Insights from applying the RESPECT \nrole-play in Austria. Climate Risk Management 35, \n100418,https://doi.org/10.1016/j.crm.2022.100418. \nSchulze, J., M\u00fcller, B., Groeneveld, J., Grimm, V., 2017. Agent-based modelling of social-\necological systems: achievements, challenges, and a way forward. Journal of Artificial Societies \nand Social Simulation 20(2), https://doi.org/10.18564/jasss.3423  \nSelfa, T., Urcuqui-Bustamante, A.M., Cordoba, D., Avila-Foucat, V.S., Pischke, E.C., Jones, \nK.W., Nava-Lopez, M.Z., Torrez, D.M., 2022. The role of situated knowledge and values in \nreshaping payment for hydrological services programs in Veracruz, Mexico: An actor-oriented \napproach. Journal of Rural Studies 95, 268-277,https://doi.org/10.1016/j.jrurstud.2022.09.012. \nShen, T., Jin, R., Huang, Y., Liu, C., Dong, W., Guo, Z., Wu, X., Liu, Y., Xiong, D., 2023. Large \nlanguage model alignment: A survey. arXiv preprint, \narXiv:2309.15025,https://doi.org/10.48550/arXiv.2309.15025. \nShen, Z., 2024. Llm with tools: A survey. arXiv preprint, arXiv:2409.18807, \nhttps://doi.org/10.48550/arXiv.2409.18807. \nSmets, P., 1997. Imperfect information: Imprecision and uncertainty, Uncertainty management in \ninformation systems: From needs to solutions. Springer, pp. 225-254. \nSpillias, S., Tuohy, P., Andreotta, M., Annand-Jones, R., Boschetti, F., Cvitanovic, C., Duggan, \nJ., Fulton, E.A., Karcher, D.B., Paris, C., 2024. Human-AI collaboration to identify literature for \nevidence synthesis. Cell Reports Sustainability 1(7),https://doi.org/10.1016/j.crsus.2024.100132. \nStampfl, R., Ivki\u0107, I., Geyer, B., 2024. Role-Playing Simulation Games using ChatGPT. arXiv \npreprint, arXiv:2402.09161,https://doi.org/10.48550/arXiv.2402.09161. \nStevenson, R., Burnell, D., Fisher, G., 2024. The minimum viable product (MVP): theory and \npractice. Journal of Management 50(8), 3202-3231,https://doi.org/10.1177/01492063241227154. \nStreamlit, 2025. A faster way to build and share data apps. https://streamlit.io/. \nSumers, T., Yao, S., Narasimhan, K., Griffiths, T., 2023. Cognitive architectures for language \nagents. Transactions on Machine Learning Research. \nTao, Y., Viberg, O., Baker, R.S., Kizilcec, R.F., 2024. Cultural bias and cultural alignment of \nlarge language models. PNAS nexus 3(9), pgae346, https://doi.org/10.1093/pnasnexus/pgae346. \nTaubenfeld, A., Dover, Y., Reichart, R., Goldstein, A., 2024. Systematic Biases in LLM"
  },
  {
    "heading": "Simulations of Debates. arXiv preprint, arXiv:2402.04049,",
    "content": "https://doi.org/10.48550/arXiv.2402.04049. \nTempleton, A., Xie, H., Gwynne, S., Hunt, A., Thompson, P., K\u00f6ster, G., 2024. Agent-based \nmodels of social behaviour and communication in evacuations: A systematic review. Safety \nScience 176, 106520,https://doi.org/10.1016/j.ssci.2024.106520. \nTeng\u00f6, M., Hill, R., Malmer, P., Raymond, C.M., Spierenburg, M., Danielsen, F., Elmqvist, T., \nFolke, C., 2017. Weaving knowledge systems in IPBES, CBD and beyond\u2014lessons learned for \nsustainability. Current opinion in environmental sustainability 26, 17-25, \nhttps://doi.org/10.1016/j.cosust.2016.12.005. \nTodd, A.R., Galinsky, A.D., 2014. Perspective\u2010taking as a strategy for improving intergroup \nrelations: Evidence, mechanisms, and qualifications. Social and Personality Psychology Compass \n8(7), 374-387,https://doi.org/10.1111/spc3.12116. \nUzochukwu, B., Onwujekwe, O., Mbachu, C., Okwuosa, C., Etiaba, E., Nystr\u00f6m, M.E., Gilson, \nL., 2016. The challenge of bridging the gap between researchers and policy makers: experiences \nof a Health Policy Research Group in engaging policy makers to support evidence informed \npolicy making in Nigeria. Globalization and health 12, 1-15, https://doi.org/10.1186/s12992-016-\n0209-1. \nVoinov, A., Bousquet, F., 2010. Modelling with stakeholders. Environmental modelling & \nsoftware 25(11), 1268-1281,https://doi.org/10.1016/j.envsoft.2010.03.007. \nWang, C.S., Ku, G., Tai, K., Galinsky, A.D., 2014. Stupid doctors and smart construction \nworkers: Perspective-taking reduces stereotyping of both negative and positive targets. Social \nPsychological and Personality Science 5(4), 430-436,https://doi.org/10.1177/19485506135049. \nWang, Z., Bi, B., Pentyala, S.K., Ramnath, K., Chaudhuri, S., Mehrotra, S., Mao, X.-B., Asur, S., \n2024. A comprehensive survey of LLM alignment techniques: RLHF, RLAIF, PPO, DPO and \nmore. arXiv preprint, arXiv:2407.16216,https://doi.org/10.48550/arXiv.2407.16216. \nWedding, L., Pittman, S., Lepczyk, C., Parrain, C., Puniwai, N., Boyle, J., Goldberg, E., Young, \nM., Marty, P., Wilhelm, K., 2024. Integrating the multiple perspectives of people and nature in \nplace-based marine spatial planning. npj Ocean Sustainability 3(1), 43, \nhttps://doi.org/10.1038/s44183-024-00071-9. \nXu, D., Chen, W., Peng, W., Zhang, C., Xu, T., Zhao, X., Wu, X., Zheng, Y., Wang, Y., Chen, \nE., 2024. Large language models for generative information extraction: A survey. Frontiers of \nComputer Science 18(6), 186357,https://doi.org/10.1007/s11704-024-40555-y. \nYe, H., Liu, T., Zhang, A., Hua, W., Jia, W., 2023. Cognitive mirage: A review of hallucinations \nin large language models. arXiv preprint, arXiv:2309.06794, \nhttps://doi.org/10.48550/arXiv.2309.06794. \nYoung, A.D., 2018. The Effects of Perspective Taking and Empathy on Moral Judgments of"
  },
  {
    "heading": "Blame and Praise. Appalachian State University.",
    "content": "Zeng, Y., 2025a. HoPeS Reflection Conversation.https://doi.org/10.5281/zenodo.16222085. \nZeng, Y., 2025b. Interactive visualization.https://yczen.github.io/data-visualization_HoPeS/. \nZeng, Y., 2025c. LlmInstitution_CRAFTY (v1.0).https://doi.org/10.5281/zenodo.14622039. \nZeng, Y., 2025d. Video of the Perspective-Taking Simulation (PTS) system. \nhttps://doi.org/10.5281/zenodo.16222595. \nZeng, Y., Brown, C., Byari, M., Raymond, J., Schmitt, T., Rounsevell, M., 2024. InsNet-\nCRAFTY v1. 0: Integrating institutional network dynamics powered by large language models \nwith land use change simulation. EGUsphere,https://doi.org/10.5194/egusphere-2024-2661. \nZeng, Y., Brown, C., Raymond, J., Byari, M., Hotz, R., Rounsevell, M., 2025a. Exploring the \nopportunities and challenges of using large language models to represent institutional agency in \nland system modelling. Earth System Dynamics 16(2), 423-449,https://doi.org/10.5194/esd-16-\n423-2025. \nZeng, Y., Raymond, J., Brown, C., Byari, M., Rounsevell, M., 2025b. Simulating endogenous \ninstitutional behaviour and policy implementation pathways within the land system. Ecological \nModelling 501, 111032, https://doi.org/10.1016/j.ecolmodel.2025.111032. \nZhao, W.X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, \nZ., 2023. A Survey of Large Language Models. arXiv preprint, arXiv:2303.18223, \nhttps://doi.org/10.48550/arXiv.2303.18223."
  }
]