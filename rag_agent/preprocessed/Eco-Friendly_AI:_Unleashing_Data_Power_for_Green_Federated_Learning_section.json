[
  {
    "heading": "Unknown",
    "content": "Eco-Friendly AI: Unleashing Data Power for Green Federated"
  },
  {
    "heading": "Unknown",
    "content": "Learning"
  },
  {
    "heading": "Unknown",
    "content": "Mattia Sabella"
  },
  {
    "heading": "Unknown",
    "content": "DEIB, Politecnico di Milano"
  },
  {
    "heading": "Milan, Italy",
    "content": "mattia1.sabella@mail.polimi.it"
  },
  {
    "heading": "Unknown",
    "content": "Monica Vitali"
  },
  {
    "heading": "Unknown",
    "content": "DEIB, Politecnico di Milano"
  },
  {
    "heading": "Milan, Italy",
    "content": "monica.vitali@polimi.it"
  },
  {
    "heading": "ABSTRACT",
    "content": "The widespread adoption of Artificial Intelligence (AI) and Machine\nLearning (ML) comes with a significant environmental impact, par-\nticularly in terms of energy consumption and carbon emissions.\nThis pressing issue highlights the need for innovative solutions to\nmitigate AI\u2019s ecological footprint. One of the key factors influenc-\ning the energy consumption of ML model training is the size of\nthe training dataset. ML models are often trained on vast amounts\nof data continuously generated by sensors and devices distributed\nacross multiple locations. To reduce data transmission costs and\nenhance privacy, Federated Learning (FL) enables model training\nwithout the need to move or share raw data. While FL offers these\nadvantages, it also introduces challenges due to the heterogeneity\nof data sources (related to volume and quality), computational node\ncapabilities, and environmental impact.\nThis paper contributes to the advancement of Green AI by propos-\ning a data-centric approach to Green Federated Learning. Specif-\nically, we focus on reducing FL\u2019s environmental impact by mini-\nmizing the volume of training data. Our methodology involves the\nanalysis of the characteristics of federated datasets, the selecting of\nan optimal subset of data based on quality metrics, and the choice\nof the federated nodes with the lowest environmental impact. We\ndevelop a comprehensive methodology that examines the influ-\nence of data-centric factors, such as data quality and volume, on\nFL training performance and carbon emissions. Building on these\ninsights, we introduce an interactive recommendation system that\noptimizes FL configurations through data reduction, minimizing\nenvironmental impact during training. Applying this methodology\nto time series classification has demonstrated promising results in\nreducing the environmental impact of FL tasks."
  },
  {
    "heading": "KEYWORDS",
    "content": "Energy-efficient data systems, Heterogeneous and federated data,"
  },
  {
    "heading": "Unknown",
    "content": "Data management support for ML, Cloud data management"
  },
  {
    "heading": "PVLDB Reference Format:",
    "content": "Mattia Sabella and Monica Vitali. Eco-Friendly AI: Unleashing Data Power\nfor Green Federated Learning. PVLDB, 14(1): XXX-XXX, 2020.\ndoi:XX.XX/XXX.XX"
  },
  {
    "heading": "PVLDB Artifact Availability:",
    "content": "This work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.\ndoi:XX.XX/XXX.XX\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/POLIMIGreenISE/ecoFL.git."
  },
  {
    "heading": "Unknown",
    "content": "1"
  },
  {
    "heading": "INTRODUCTION",
    "content": "The rapid proliferation of Artificial Intelligence (AI) and Machine\nLearning (ML) has transformed the digital landscape, particularly\nwith the emergence of large-scale models such as ChatGPT, which\nhave captured global attention. This growth coincides with the ex-\npansion of ubiquitous, low-latency communication enabled by 5G\ntechnology and the Internet of Things (IoT), where vast amounts of\ndata are continuously generated by distributed smart devices. Man-\naging this explosion of data efficiently requires scalable cloud, edge,\nand fog computing solutions that balance computation, storage,\nfault tolerance, and privacy."
  },
  {
    "heading": "However, the increasing computational power required for Deep",
    "content": "Learning (DL) raises significant energy efficiency challenges, mak-\ning AI\u2019s environmental impact an urgent concern. As AI-driven\napplications become more pervasive, it is crucial to transition from\na performance-first approach (Red AI) to a sustainability-focused\nparadigm (Green AI) [42]. This shift demands new strategies for op-\ntimizing AI workflows, particularly in data management, to reduce\nenergy consumption while maintaining model performance.\nOne key factor influencing ML efficiency is data quality. In large-\nscale, distributed environments, traditional data pre-processing\nmethods must be re-evaluated to account for heterogeneous data\nsources, privacy constraints, and resource limitations. Federated\nLearning (FL) has emerged as a promising solution, enabling decen-\ntralized model training without requiring raw data to be transferred\nto a central server. However, FL also introduces new complexities\ndue to variations in data quality, volume, and computational capa-\nbilities across participating nodes.\nThis paper proposes a data-centric approach to energy-efficient\nFederated Learning, addressing the environmental footprint of FL\nwhile maintaining ML performance. We investigate the role of data\nquality measures at each network node and develop a methodol-\nogy to optimize data selection in the FL process, aiming to reduce\nthe energy consumption and carbon emissions of AI training in a\nfederated environment.\n1.1"
  },
  {
    "heading": "Scope and Contribution",
    "content": "This work contributes to energy-efficient data management for ML\nin heterogeneous and federated environments, by exploring how\ndata management techniques can enhance the energy efficiency of"
  },
  {
    "heading": "FL. Specifically, we:",
    "content": "\u2022 Analyze data quality characteristics and their impact on FL\nmodel performance and energy consumption;\narXiv:2507.17241v1  [cs.LG]  23 Jul 2025\n\u2022 Develop a data-centric methodology to optimize training\ndata selection, reducing unnecessary computation while\npreserving model accuracy;\n\u2022 Evaluate energy and carbon footprint reduction through\nextensive experiments on time-series classification tasks.\nThis research aims to empower AI practitioners and researchers\nto incorporate energy-efficient data management strategies into FL\napplications, ensuring distributed ML sustainable scaling."
  },
  {
    "heading": "Unknown",
    "content": "2"
  },
  {
    "heading": "STATE OF THE ART",
    "content": "Artificial Intelligence (AI) has become pervasive across diverse do-\nmains, offering transformative solutions while also contributing\nsignificantly to the environmental footprint of IT systems [40]. The\ncomputational demands of AI have escalated dramatically over\nthe past decade, increasing by a staggering 300,000-fold, primarily\ndue to the growth of Deep Learning (DL) and Deep Neural Net-\nworks (DNNs) [17, 19, 26, 44]. The environmental impact of AI\nhas been critically examined by Schwartz et al. [42], who intro-\nduced the paradigms of Red AI and Green AI. Red AI prioritizes\nperformance at any computational cost, while Green AI empha-\nsizes resource-efficient AI practices, advocating for sustainable AI\ndevelopment. Several studies have explored the carbon footprint of\nAI from various perspectives: Georgiou et al. [14] examine infras-\ntructure, architecture, and geographic considerations, while Frey\net al. [13] investigate the impact of model selection and hyperpa-\nrameter tuning. The often-overlooked environmental cost of data\npreparation is highlighted by Castanyer et al. [9]."
  },
  {
    "heading": "Data-Centric AI shifts the focus from model optimization to",
    "content": "data quality, aiming to enhance training datasets [23, 53]. Whang\net al. [50] propose a data-centric approach for DL, emphasizing ro-\nbustness against noisy datasets. Effective data preparation is crucial\nfor large-scale analytics [32, 34], influencing both model perfor-\nmance [27, 43] and dataset balance [49]. The significance of data\nmanagement techniques in ML is emphasized in [38], where a com-\nprehensive survey of data cleaning and preparation approaches is\nprovided. The inefficiencies caused by excessive data are discussed\nin [11], highlighting that large datasets can inflate training times\nand energy consumption with diminishing returns [31, 45]. Chai et\nal. [10] propose a two-step strategy: a data-effective step to enhance\ndata quality and a data-efficiency step to reduce dataset size while\npreserving accuracy."
  },
  {
    "heading": "Reducing dataset size can significantly lower energy consump-",
    "content": "tion, as demonstrated in a study on Green AI [47], which main-\ntains competitive accuracy despite dataset reductions. Effective\ndata selection requires leveraging Data Quality (DQ) metrics, as\npoor-quality data can bias models and degrade reliability [5, 15, 22].\nBudach et al. [8] analyze the impact of DQ issues such as com-\npleteness, accuracy, consistency, and class balance, showing that\nclass balancing becomes critical only with significant imbalances.\nAnselmo et al. [3] propose a recommender system that reduces the\nenvironmental impact of DL while maintaining target accuracy by\nconsidering both data volume and quality.\nFederated Learning (FL) is a distributed paradigm that enables\ncollaborative model training without centralizing data, introduced\nin [7] to preserve data privacy and minimize transmission costs.\nA comprehensive classification of FL systems is presented in [29],\nexamining aspects such as data distribution, ML models, privacy\nmechanisms, communication, scalability, and federation motivation.\nFL has been applied in contexts including ranking algorithms [48],\nfederated numerical aggregation [12], and Knowledge Graph Em-\nbedding [18]. However, FL faces challenges from data heterogeneity,\nwhich can degrade model performance [25, 28, 30, 52]."
  },
  {
    "heading": "The environmental impact of FL is multifaceted[41]. While its",
    "content": "decentralized nature can exploit energy-efficient edge devices, the\noverhead from communication and device heterogeneity can result\nin emissions up to two orders of magnitude higher than central-\nized training [39]. Carbon-aware scheduling approaches, such as\nFedZero [51], dynamically select FL execution locations based on\nreal-time energy mix variations, reducing emissions by relying on\nrenewable resources. Similarly, Abbasi et al. [2] propose a green FL\napproach that adapts model size based on regional carbon intensity\nand introduces ordered dropout techniques for emissions reduction.\nMao et al. [33] explore energy-efficient methodologies for edge AI,\nidentifying key energy consumption contributors.\nIn summary, existing research focuses primarily on system-level\nenhancements [7, 46] or data-centric strategies in centralized ML [3,\n47]. The interplay between dataset characteristics (e.g., volume,\nquality) and environmental impact in FL remains underexplored.\nThis paper addresses this gap by introducing a federated, data-\ncentric framework that:\n\u2022 Analyzes the impact of dataset volume and quality on"
  },
  {
    "heading": "FL emissions, optimizing training configurations.",
    "content": "\u2022 Selects data subsets and participant nodes based on\nenvironmental and computational efficiency.\n\u2022 Optimizes FL training through an interactive recom-\nmender system.\nThis work bridges data-centric AI and Federated Learning, offer-\ning a scalable template for sustainable FL deployment, advancing\nthe intersection of energy-efficient data systems, heterogeneous and\nfederated data management, and cloud-based AI sustainability."
  },
  {
    "heading": "Unknown",
    "content": "3"
  },
  {
    "heading": "APPROACH OVERVIEW",
    "content": "Federated Learning (FL) offers a decentralized approach to train-\ning deep learning models, preserving data locality and reducing\nthe need for massive data transfers to a central server. This paper\ninvestigates an FL system implemented on a fog computing archi-\ntecture, where computational tasks are distributed among hetero-\ngeneous nodes spanning the cloud continuum. These nodes, each\nwith distinct hardware capabilities, energy efficiency, and carbon\nfootprints, play a crucial role in optimizing both performance and\nsustainability. The considered scenario is shown in Fig. 1. Despite\nits advantages, FL does not inherently ensure energy efficiency. The\ndistributed nature of FL training introduces challenges, including\nincreased energy consumption due to system and statistical hetero-\ngeneity. Additionally, the geographical distribution of nodes affects\ncarbon emissions, as energy sources vary by region. Selecting ap-\npropriate nodes for training is therefore essential to minimizing\nenvironmental impact.\nAnother critical factor in FL performance and sustainability is\nth quality and volume of data distributed across nodes. Training\na deep learning model with low-quality data can introduce biases,"
  },
  {
    "heading": "Unknown",
    "content": "2"
  },
  {
    "heading": "Unknown",
    "content": "GLOBAL"
  },
  {
    "heading": "Unknown",
    "content": "MODEL"
  },
  {
    "heading": "Unknown",
    "content": "LOCAL"
  },
  {
    "heading": "Unknown",
    "content": "MODELS"
  },
  {
    "heading": "Unknown",
    "content": "EDGE"
  },
  {
    "heading": "Unknown",
    "content": "DEVICES"
  },
  {
    "heading": "Unknown",
    "content": "NODE 1"
  },
  {
    "heading": "Unknown",
    "content": "NODE 2"
  },
  {
    "heading": "Unknown",
    "content": "NODE 3"
  },
  {
    "heading": "Figure 1: Scenario overview",
    "content": "reducing model accuracy while consuming unnecessary computa-\ntional resources. Existing research [3][8] suggests that reducing\ntraining set volume can lower energy consumption in centralized\nsettings, but FL\u2019s inherent heterogeneity complicates this approach.\nIn an FL scenario, data volume and quality are intertwined with\nnode selection.\nThis paper explores two key strategies for optimizing FL training:\n\u2022 Horizontal Data Reduction: Applying data volume reduc-\ntion and quality improvement uniformly across all nodes;\n\u2022 Vertical Data Reduction: Selecting a subset of nodes for\ntraining based on their energy efficiency and data quality."
  },
  {
    "heading": "This paper investigates the environmental impact of FL algo-",
    "content": "rithms within a Fog Computing infrastructure, characterized by\nhigh heterogeneity in both hardware (performance, energy con-\nsumption, and energy mix) and data (volume and quality) across\nparticipating nodes. Adopting a data-centric perspective, this\nstudy defines two key objectives:\n\u2022 Goal 1: Analyze the data-centric impact on energy con-\nsumption and performance in an FL setting by conducting\na detailed evaluation of the FL model. This includes assess-\ning how variations in data volume and quality influence\nmodel accuracy and carbon emissions within an FL config-\nuration;\n\u2022 Goal 2: Reduce carbon emissions in FL by proposing a\nmethodology for efficient node and data selection while\nensuring that the FL algorithm maintains a predefined per-\nformance level."
  },
  {
    "heading": "Experiments are conducted in a simulated FL environment, al-",
    "content": "lowing for controlled evaluation of data-centric impacts on energy\nconsumption and performance. The findings are then adapted to\nreal-world scenarios, where intelligent node selection and data re-\nduction methodologies are proposed to ensure sustainability with-\nout compromising model accuracy."
  },
  {
    "heading": "By developing a general methodology applicable to various FL",
    "content": "settings, this work aims to provide researchers with actionable"
  },
  {
    "heading": "Figure 2: FL Configuration Selection System Architecture.",
    "content": "recommendations for reducing FL\u2019s carbon footprint while main-\ntaining training efficiency. The proposed FL Configuration Selec-\ntion System enables informed decisions on node selection and data\nmanagement, balancing environmental impact with computational\neffectiveness."
  },
  {
    "heading": "Unknown",
    "content": "4"
  },
  {
    "heading": "GREEN FL METHODOLOGY",
    "content": "To achieve the predefined goals, this paper proposes a FL Configu-\nration Selection System designed to provide recommendations\nand predictions for minimizing the environmental impact of FL\ntraining. This system focuses on two key actions:\n(1) Optimizing data volume: Recommending appropriate re-\nductions in training data volume to lower the environmen-\ntal cost of the training process while ensuring the resulting\nmodel meets predefined accuracy constraints;\n(2) Selecting efficient client nodes: Identifying optimal client\nnodes based on their energy efficiency, environmental im-\npact, and data quality characteristics.\nA researcher can use this approach by providing all the necessary\ninput concerning the dataset characteristics and the FL architecture\nand obtaining an environmentally sustainable FL configuration. The\nmethodology, shown in Fig. 2, unfolds in three sequential phases: (i)"
  },
  {
    "heading": "Data-Centric FL Exploration; (ii) Data Analysis and Modeling;",
    "content": "and (iii) FL Configuration Recommendation."
  },
  {
    "heading": "The Data-Centric FL Exploration Phase leverages an FL simu-",
    "content": "lation environment to analyze system training under various dataset\nand data-centric configurations. The primary objective is to under-\nstand how data volume and data quality influence FL system perfor-\nmance and energy consumption during training. Simulation results\nare processed to construct curves that capture the relationships\nbetween data characteristics, final model accuracy, and energy con-\nsumption. These experimental findings and corresponding curves\nare stored for subsequent analysis."
  },
  {
    "heading": "In the Data Analysis and Modeling Phase, the obtained re-",
    "content": "sults are analyzed in terms of performance and energy impact. This"
  },
  {
    "heading": "Unknown",
    "content": "3"
  },
  {
    "heading": "Figure 3: FL Simulator: Sub-experiment generation process",
    "content": "analysis leads to the development of a predictor capable of rec-\nommending optimal dataset size reductions for unseen datasets\nprovided by researchers within a Federated Learning setting."
  },
  {
    "heading": "The subsequent FL Configuration Recommendation Phase",
    "content": "tailors predictions to the specific execution context defined by the\nresearcher. This phase introduces an FL Configuration Recom-\nmender, which considers the characteristics of the infrastructure\u2019s\nnodes and the data subsets they contain.\nThe architecture of the proposed approach is illustrated in Fig. 2,\nwith its components structured according to the three phases.\n4.1"
  },
  {
    "heading": "Unknown",
    "content": "Data-Centric FL Exploration"
  },
  {
    "heading": "The Data-Centric FL Exploration phase is an exploratory stage",
    "content": "where the proposed system empirically identifies relevant patterns\nin Federated Learning (FL) training. At the core of this phase is\nthe FL Simulator, which executes experiments to assess the perfor-\nmance and energy impact of FL systems under various data-centric\nconfigurations (Fig. 3). The simulator replicates a federated envi-\nronment, consisting of a central server and multiple participant\nnodes. Experiments are conducted across multiple datasets, with\neach \ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc61undergoing structured sub-experiments to analyze\nthe effects of a specific data \ud835\udc37\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5bconfigurations.\n\ud835\udc38\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61= {\ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc61,\ud835\udc47\ud835\udc66\ud835\udc5d\ud835\udc52, \ud835\udc37\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b} : \ud835\udc47\ud835\udc66\ud835\udc5d\ud835\udc52\u2208{\ud835\udc49, \ud835\udc3b}\n(1)\n\ud835\udc46\ud835\udc62\ud835\udc4f_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61= {\ud835\udc38\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61, \ud835\udc37\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b_\ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc53\ud835\udc56\ud835\udc54\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b}\n(2)\nFor each experiments, sub-experiments are conducted by degrading\na specific data-related dimension \ud835\udc37\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc5c\ud835\udc5b_\ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc53\ud835\udc56\ud835\udc54\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b(e.g.,\nvolume, accuracy, consistency, and completeness). For instance ,\nthe volume can be gradually reduced to evaluate its impact on\nmodel accuracy and energy consumption. Two experiment \ud835\udc61\ud835\udc66\ud835\udc5d\ud835\udc52\ud835\udc60\nare considered: (i) in vertical experiments (\ud835\udc49), data quality and\nvolume variations affect only a subset of the participating nodes; (ii)\nin horizontal experiments (\ud835\udc3b), variations impact all nodes uniformly.\nThe results are stored in the Experiments database and further\nprocessed by the Curves Extractor to identify patterns from each\nexperiment using a logarithmic regression model. The results of\nthese analysis are saved in the Curves Dataset in the format:\n\ud835\udc36\ud835\udc62\ud835\udc5f\ud835\udc63\ud835\udc52= {\ud835\udc38\ud835\udc65\ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc56\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61, \ud835\udc40\ud835\udc52\ud835\udc61\ud835\udc5f\ud835\udc56\ud835\udc50, \ud835\udc45\ud835\udc52\ud835\udc54\ud835\udc5f\ud835\udc52\ud835\udc60\ud835\udc60\ud835\udc5c\ud835\udc5f_\ud835\udc5d\ud835\udc4e\ud835\udc5f\ud835\udc4e\ud835\udc5a\ud835\udc52\ud835\udc61\ud835\udc52\ud835\udc5f\ud835\udc60}\n(3)\nwhere \ud835\udc40\ud835\udc52\ud835\udc61\ud835\udc5f\ud835\udc56\ud835\udc50refer to energy or accuracy. The example in Fig. 4\ndemonstrates the relationship between the data volume and the\naccuracy for an experiment.\n4.2"
  },
  {
    "heading": "Data Analysis and Modelling",
    "content": "The aim of the Data Analysis and Modeling phase is to generalize\nthe findings from the exploratory phase and develop models for\nfuture recommendations."
  },
  {
    "heading": "Unknown",
    "content": "Figure 4: Data volume vs Accuracy pattern example"
  },
  {
    "heading": "The Data Analyzer component examines how accuracy and en-",
    "content": "ergy metrics respond to variations in data volume and quality,\nanalyzing patterns in the Curves Dataset. The analysis produces: (i)\nthe selection of the most effective approach (horizontal or vertical)\nto maximize data volume reduction while maintaining high accu-\nracy; (ii) a ranking of the impact of different data dimensions on\nmodel performance to identify the most influential factors."
  },
  {
    "heading": "The Training component builds a machine learning regressor to",
    "content": "predict the required data volume reduction for an unseen FL config-\nuration while maintaining a predefined accuracy level. The model\ntakes as input features of the dataset (e.g., dataset type, number of\ntraining samples, sequence length, and number of classes) along\nwith the desired accuracy. The target variable is the data volume\nnecessary to achieve the specified accuracy. The resulting FL Reduc-\ntion System component, enables researchers to optimize FL training\ntasks within a distributed infrastructure. Given a target accuracy,\nthis component predicts the best data-centric configuration (i.e.,\ndata volume reduction and number of participating nodes) needed\nto meet the specified accuracy threshold.\n4.3"
  },
  {
    "heading": "FL Configuration Recommendation",
    "content": "The FL Configuration Recommendation phase refines the predictions\nfrom the FL Reduction System to tailor them to the specific FL task\ndefined in the Dataset and FL Setting Info. The researcher provides:\n\u2022 Dataset description: total volume, type, and number of\nclasses.\n\u2022 FL participant node details: hardware specifications (CPU,"
  },
  {
    "heading": "GPU, RAM), power consumption, geographical location,",
    "content": "carbon intensity of the energy source, and data volume/quality\nmetrics (e.g., accuracy, consistency, completeness).\n\u2022 Initial accuracy estimation: obtained by training the\nmodel on a single node to establish a baseline for expected\nperformance.\n\u2022 Accuracy threshold: target performance for FL training.\nThis phase optimizes FL training by selecting the most suitable\nsubset of data and participant nodes, ensuring minimal environmen-\ntal impact while maintaining model performance. The FL Configu-\nration Recommender ranks nodes based on carbon emissions and\ndataset quality, applying data reduction strategies recommended\nby the FL Reduction System. It then selects the optimal set of nodes\nand filters datasets to retain only high-quality data, streamlining\nthe training process for efficiency and sustainability.\n4"
  },
  {
    "heading": "Unknown",
    "content": "5"
  },
  {
    "heading": "Unknown",
    "content": "IMPLEMENTATION FOR TIME SERIES"
  },
  {
    "heading": "CLASSIFICATION",
    "content": "The proposed approach is applicable to various types of machine\nlearning tasks. However, for evaluation purposes, we selected a spe-\ncific FL application: Time Series Classification. This task was chosen\nbecause it aligns well with FL scenarios, where large volumes of\ndata are generated by multiple devices across different locations."
  },
  {
    "heading": "For local training, we employ a Deep Learning model based",
    "content": "on ResNet. The performance of the FL model is assessed using\nthe accuracy metric. Energy consumption is measured in kilowatt-\nhours (kWh), while carbon emissions are computed based on energy\nusage and the carbon intensity of each node\u2019s location, expressed\nin kilograms of CO2 equivalents (kg CO2e).\n5.1"
  },
  {
    "heading": "Unknown",
    "content": "Data-Centric FL Exploration"
  },
  {
    "heading": "The Data-Centric FL Exploration phase involves simulating",
    "content": "model training on diverse and heterogeneous datasets. The datasets\nused in the FL Simulator to generate experiments for analysis in\nthe Data Analyzer were sourced from the UCR/UEA archive1. For\nthis study, we selected five datasets, each adapted to the FL setting\nby evenly distributing the training samples across client nodes. The\nkey characteristics of these datasets are summarized in Table 1."
  },
  {
    "heading": "The FL Simulator has been implemented using the Flower frame-",
    "content": "work [6], which enables the simulation of multiple nodes on a single\nsystem while managing the transmission and aggregation of train-\ning parameters. In this phase, a fixed FL configuration with 10 nodes\nhas been used. The dataset is evenly distributed among all client\nnodes, with each subset further divided into a training set (90%)\nand a validation set (10%) for local model training. Additionally, the\noriginal dataset\u2019s test set is distributed across all clients."
  },
  {
    "heading": "At the end of each training round and upon completion of the",
    "content": "entire FL training process, a validation step is performed. After\neach round, the local model is validated using the local test set,\nwhile the global model is evaluated against a disjoint global test set.\nExperiments are executed for each dataset, as defined in Eq. 1 and"
  },
  {
    "heading": "Eq. 2, with three executions per configuration.",
    "content": "To analyze the effect of data-centric configurations, controlled\ndegradations were applied by injecting errors into various data\nproperties. Each property was modified gradually, from 0% to 80%,\nin increments of 20%. At the end of each experiment, accuracy and\nenergy consumption metrics were recorded, and the results were\nstored in the Curves Dataset. The following key data properties\nwere explored:\n\u2022 Data Volume: Proportion of the dataset used during train-\ning relative to the original dataset size:\n\ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc49\ud835\udc5c\ud835\udc59\ud835\udc62\ud835\udc5a\ud835\udc52=\n#\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n#\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n(4)"
  },
  {
    "heading": "Data volume is reduced by randomly removing samples",
    "content": "from the training set until the desired size is reached.\n\u2022 Data Accuracy: Proportion of correctly labeled samples in\nthe dataset:\n\ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc34\ud835\udc50\ud835\udc50\ud835\udc62\ud835\udc5f\ud835\udc4e\ud835\udc50\ud835\udc66= 1 \u2212#\ud835\udc5a\ud835\udc56\ud835\udc60\ud835\udc59\ud835\udc4e\ud835\udc4f\ud835\udc52\ud835\udc59\ud835\udc59\ud835\udc52\ud835\udc51_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n#\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n(5)\n1https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/"
  },
  {
    "heading": "Label noise is introduced by modifying a subset of labels to",
    "content": "incorrect values.\n\u2022 Data Consistency: Fraction of consistent data points in\nthe dataset:\n\ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc36\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc60\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc66= 1 \u2212#\ud835\udc56\ud835\udc5b\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc60\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc61_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n#\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n(6)"
  },
  {
    "heading": "Inconsistency is introduced by duplicating samples and",
    "content": "assigning them conflicting labels.\n\u2022 Data Completeness: Proportion of available (non-null)\ndata points:\n\ud835\udc37\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc36\ud835\udc5c\ud835\udc5a\ud835\udc5d\ud835\udc59\ud835\udc52\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc52\ud835\udc60\ud835\udc60= 1 \u2212#\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60_\ud835\udc64\ud835\udc56\ud835\udc61\u210e\ud835\udc5a\ud835\udc56\ud835\udc60\ud835\udc60\ud835\udc56\ud835\udc5b\ud835\udc54\ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc62\ud835\udc52\ud835\udc60\n#\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc54\ud835\udc56\ud835\udc5b\ud835\udc4e\ud835\udc59_\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc5c\ud835\udc56\ud835\udc5b\ud835\udc61\ud835\udc60\n(7)"
  },
  {
    "heading": "Completeness degradation is applied by randomly selecting",
    "content": "data points and replacing portions of their sequences with\nnull values.\nAs discussed in Sect. 4.1, injections are distributed both horizon-\ntally and vertically among the participating nodes.\n5.2"
  },
  {
    "heading": "Unknown",
    "content": "Data Analysis and Modelling"
  },
  {
    "heading": "The Data Analyzer component is responsible for examining the",
    "content": "results and trends obtained from the experiments. For each data\nproperty, it compares the impact of horizontal and vertical ap-\nproaches on both accuracy and energy consumption."
  },
  {
    "heading": "The first comparison focuses on the relationship between data",
    "content": "volume and model accuracy (Fig. 5). Results show that the ver-\ntical approach consistently achieves higher or equal accuracy\ncompared to the horizontal approach."
  },
  {
    "heading": "The trade-off between data volume and energy consumption",
    "content": "is illustrated in Fig. 6. Similar to the previous analysis, the vertical\napproach demonstrates a lower environmental impact due to the\nreduced number of participating nodes.\nAdditionally, experiments have examined the impact of data qual-\nity dimensions. Findings from [8] and [3] suggest that different data\nquality aspects influence training differently, with accuracy and\nconsistency being more critical than completeness. Experimental\nresults confirm that these trends hold in the FL setting.\nIn conclusion, the vertical approach proved to be the preferred\nstrategy, as it maintains higher model accuracy while reducing\nenergy consumption. Therefore, it will serve as the baseline for the\nsubsequent steps of the methodology."
  },
  {
    "heading": "The Training component builds a regression model to predict",
    "content": "the required data volume needed to achieve a desired accuracy\nlevel for unseen datasets. Under the selected vertical configura-\ntion, this corresponds to determining the optimal number of nodes\nto participate in the training process. The model features include:\ndataset type, number of training samples, sequence length,\nand number of classes. To identify the most suitable regression\nmodel for this task, a hyperparameter search approach was em-\nployed, evaluating multiple machine learning algorithms, including\nLinear Regression, Lasso, Ridge, ElasticNet, Random Forest, Decision\nTree, Gradient Boosting, and XGBoost Regressor. The model with the\nlowest test error, Gradient Boosting, was ultimately selected."
  },
  {
    "heading": "Unknown",
    "content": "5"
  },
  {
    "heading": "Unknown",
    "content": "Name"
  },
  {
    "heading": "Unknown",
    "content": "Train Size"
  },
  {
    "heading": "Unknown",
    "content": "Classes"
  },
  {
    "heading": "Unknown",
    "content": "Sequence Length"
  },
  {
    "heading": "Unknown",
    "content": "Type"
  },
  {
    "heading": "StarlightCurves",
    "content": "8236\n3\n1024"
  },
  {
    "heading": "Unknown",
    "content": "Sensor"
  },
  {
    "heading": "ChlorineConcentration",
    "content": "3840\n3\n166"
  },
  {
    "heading": "Unknown",
    "content": "Simulated"
  },
  {
    "heading": "PhalangesOutlinesCorrect",
    "content": "1800\n2\n80"
  },
  {
    "heading": "Unknown",
    "content": "Image"
  },
  {
    "heading": "Yoga",
    "content": "3000\n2\n426"
  },
  {
    "heading": "Unknown",
    "content": "Image"
  },
  {
    "heading": "ItalyPowerDemand",
    "content": "1029\n2\n24"
  },
  {
    "heading": "Unknown",
    "content": "Sensor"
  },
  {
    "heading": "Unknown",
    "content": "Table 1: Summary of the datasets used in FL experiments."
  },
  {
    "heading": "Figure 5: Accuracy and Data Volume trade-off.",
    "content": "5.3"
  },
  {
    "heading": "FL Configuration Recommendation",
    "content": "The FL Configuration Recommendation phase aims to minimize the\ncarbon footprint while maintaining the required performance level\nfor a specific training task submitted by a researcher.\nThe researcher provides the FL configuration data as input, in-\ncluding for each node: power profile, geographical location, dataset\nvolume, and data quality. Based on this information, the component\nrecommends an optimized FL configuration by selecting the most\nsuitable nodes and allocating dataset portions for FL training."
  },
  {
    "heading": "The FL Configuration Recommender utilizes the model generated",
    "content": "by the FL Reduction System to predict the number of nodes ( \u02c6\ud835\udc41)\nrequired to achieve the desired performance level, based on the\ndataset characteristics provided by the researcher. This prediction\nassumes a homogeneous FL configuration, where all nodes have the\nsame data volume and quality. However, in real-world scenarios,\ndata distribution is often heterogeneous across nodes in terms of\nboth volume and quality, necessitating further adjustments."
  },
  {
    "heading": "As a first step, the FL Configuration Recommender ranks nodes",
    "content": "according to their environmental impact and data quality. The score"
  },
  {
    "heading": "Unknown",
    "content": "6"
  },
  {
    "heading": "Figure 6: Energy and Data Volume trade-off.",
    "content": "assigned to each node, \ud835\udc46\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52\ud835\udc5b, is computed as follows:\n\ud835\udc46\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52\ud835\udc5b= \ud835\udc4a\ud835\udc38\u00b7 (1 \u2212\n\ud835\udc36\ud835\udc42\ud835\udc5b\n2\n\ud835\udc40\ud835\udc4e\ud835\udc65\ud835\udc36\ud835\udc422\n) +\n\ud835\udc3c\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4a\ud835\udc56\u00b7 \ud835\udc44\ud835\udc5b\n\ud835\udc56\n(8)\nwhere \ud835\udc36\ud835\udc42\ud835\udc5b\n2 represents the environmental footprint of node \ud835\udc5b, while\n\ud835\udc40\ud835\udc4e\ud835\udc65\ud835\udc36\ud835\udc422 denotes the footprint of the node with the highest environ-\nmental impact. Similarly, \ud835\udc44\ud835\udc5b\n\ud835\udc56corresponds to the quality dimension \ud835\udc56\nfor the dataset in node \ud835\udc5b. The terms\ud835\udc4a\ud835\udc38and\ud835\udc4a\ud835\udc56are weights assigned\nto the carbon emissions of the node and the data quality properties\n(e.g., consistency and completeness), respectively. The sum of these\nweights must be equal to 1. In this study, the weights have been\nset to prioritize the contribution of energy consumption. Once the\nscores are computed, nodes can be ranked accordingly."
  },
  {
    "heading": "The predicted number of nodes, \u02c6\ud835\udc41, must be adapted to fit the",
    "content": "FL configuration specified by the researcher. To achieve this, we\nintroduce two key metrics:\n\u2022 Basic Data Volume Percentage, \ud835\udc49\ud835\udc5b: This represents the\npercentage of the total dataset assigned to a single node \ud835\udc5b\nand is defined as:\n\ud835\udc49\ud835\udc5b=\n1\n\ud835\udc41\ud835\udc36\n(9)\nwhere \ud835\udc41\ud835\udc36is the total number of nodes in the FL task.\n\u2022 Target Data Volume Percentage, \ud835\udc49: This denotes the\ntotal proportion of the dataset recommended for use by the\nsystem and is computed as:\n\ud835\udc49= \u02c6\ud835\udc41\u00b7 \ud835\udc49\ud835\udc5b\n(10)\nThese metrics ensure that, in a heterogeneous scenario, the pre-\ndicted number of nodes \u02c6\ud835\udc41allows for the selection of the target data\nvolume necessary \ud835\udc49for an effective FL training.\nAt this stage, the component must select the specific set of nodes\nto be used in the FL training. Three selection methods are proposed\nand compared:\n\u2022 Node Selection (NS): This method selects the first \u02c6\ud835\udc41nodes\nwith the highest score. The selected nodes must satisfy\nthe required data volume percentage \ud835\udc49\ud835\udc5b. If a node \ud835\udc5bhas\na dataset larger than the required \ud835\udc49\ud835\udc5b, its data volume is\nrandomly reduced to match \ud835\udc49\ud835\udc5b. Conversely, if a node\u2019s data\nvolume does not meet the requirement, it is excluded in\nfavor of the next candidate in the ranking.\n\u2022 Minimal Smart Reduction (MSR): This method follows\nthe same strategy as NS but incorporates data cleaning by\n7\nremoving low-quality (dirty) data. Only clean data are used\nfor training. As a consequence, the effective data volume\n\ud835\udc38, which is the sum of the clean data volumes from the\nselected nodes, may be lower than the target volume \ud835\udc49,\npotentially impacting model accuracy.\n\u2022 Smart Reduction (SR): This method extends MSR by en-\nsuring that the target data volume \ud835\udc49is met. Since remov-\ning low-quality data may reduce the total data volume\n(\ud835\udc38< \ud835\udc49), SR compensates by selecting additional nodes\nuntil \ud835\udc38reaches or exceeds \ud835\udc49.\nThe effectiveness of these three methods is evaluated in Sec. 6."
  },
  {
    "heading": "Unknown",
    "content": "6"
  },
  {
    "heading": "VALIDATION",
    "content": "The evaluation is conducted by simulating both the role of the\nresearcher and a real-world fog computing scenario. In this context,\na set of heterogeneous nodes is considered, each differing in data\nproperties, geographical location, and power consumption.\nThe considered scenario sees a researcher with a pre-defined FL\nconfiguration aiming at reducing energy costs and optimizing FL\ntraining from a data-centric perspective. To support this task, the\nresearcher would use the proposed FL Configuration Selection Sys-\ntem, providing the inputs listed in Sect. 4.3, including: the dataset\ndescription; the FL participant nodes details; the accuracy estima-\ntion; and the accuracy threshold. Additionally, she can provide the\nweights to be associated with energy and data quality in the scoring\nof the nodes (Tab. 3).\nFor evaluation purposes, three distinct FL initial configurations\nhave been tested using three different datasets (Tab. 2). These config-\nurations, referred to as Configuration 1, Configuration 2, and Con-\nfiguration 3 (Tab. 4), incorporate heterogeneous nodes distributed\nacross different global regions, each with varying hardware capabil-\nities and data quality levels. The power-related measurements are\nderived from the real specifications of existing GPU and TPU de-\nvices. While the carbon intensity for each location is not explicitly\nlisted, it is obtained from [1] and utilized to compute the actual car-\nbon emissions generated during training. Each FL configuration is\npaired with a specific dataset: FreezerRegularTrain, TwoLeadECG,\nand ElectricDevices, respectively.\nThe initial accuracy estimation is computed by selecting one ran-\ndom client and training it for a full FL cycle with just one node. The\naccuracy estimation performance value reports only an indication\nof the pattern and capabilities of satisfying the task, therefore only\nan approximated accuracy value is returned.\nUsing the described datasets and configurations, the three pro-\nposed approaches have been tested and compared against a baseline.\nThe Baseline approach is defined as training without any optimiza-\ntion techniques applied; thus, it corresponds to training the original\nFL configuration using all available resources and data. The results\npresent a direct comparison of the four methods: Baseline, NS,\nSR, and MSR. The evaluation is based on two key metrics relevant\nto this study: (i) the carbon emissions produced by the overall FL\nsystem during both the pre-processing and training phases, and (ii)\nthe final accuracy achieved in predicting a disjoint test set by the\ntrained FL configuration. The results will be analyzed by evaluating\neach configuration individually, comparing final accuracy and car-\nbon emissions. The validation experiments have been conducted by"
  },
  {
    "heading": "Unknown",
    "content": "Figure 7: Configuration 1 Accuracy Results."
  },
  {
    "heading": "Figure 8: Configuration 1 Carbon Emissions Results.",
    "content": "running and repeating each experiment 8 times. Given that there\nare three FL configurations, three proposed methods, and the Base-\nline approach applied to each configuration, the total number of\nsimulations performed for the validation amounts to 96.\n6.1"
  },
  {
    "heading": "Configuration 1",
    "content": "The first evaluation experiment was conducted using Configuration\n1 (Tab. 4) with the FreezerRegularTrain dataset (Tab. 2). As a first\nstep, the accuracy estimation was performed, yielding a result of\n0.81 with emissions of 0.03 kg \ud835\udc36\ud835\udc422e. As a realistic objective, the\naccuracy threshold set by the researcher was assumed to be 0.85.\nThe results are presented in Fig. 7, which illustrates the dis-\ntribution of accuracies obtained using the Baseline and the three\nproposed recommender systems. The red dashed line represents the\naccuracy threshold set at 0.85. The plot demonstrates that the Base-\nline approach, which utilizes all available resources (i.e., all nodes\nwithout dataset manipulation), meets the accuracy constraint seven\ntimes out of eight. Notably, the three recommender systems achieve\neven better results while using fewer resources. The Minimal Smart\nReduction recommender, in particular, satisfies the researcher\u2019s con-\nstraint in seven out of eight cases, matching the Baseline. Overall,\na slight improvement in accuracy can be observed with a reduced\nresource footprint, particularly when leveraging cleaner data."
  },
  {
    "heading": "The comparison of carbon emissions impact is shown in Fig. 8.",
    "content": "As expected, the Baseline, utilizing all nodes and the entire dataset,"
  },
  {
    "heading": "Unknown",
    "content": "8"
  },
  {
    "heading": "Unknown",
    "content": "Name"
  },
  {
    "heading": "Unknown",
    "content": "Type"
  },
  {
    "heading": "Unknown",
    "content": "Train Samples"
  },
  {
    "heading": "Unknown",
    "content": "Sequence"
  },
  {
    "heading": "Unknown",
    "content": "Classes"
  },
  {
    "heading": "Unknown",
    "content": "Accuray Estimation"
  },
  {
    "heading": "Unknown",
    "content": "FreezerRegularTrain"
  },
  {
    "heading": "Sensor",
    "content": "2350\n301\n2\n0.81"
  },
  {
    "heading": "TwoLeadECG",
    "content": "ECG\n1039\n82\n2\n0.70"
  },
  {
    "heading": "Unknown",
    "content": "ElectricDevices"
  },
  {
    "heading": "Device",
    "content": "8894\n96\n7\n0.53"
  },
  {
    "heading": "Unknown",
    "content": "Table 2: Evaluation Datasets."
  },
  {
    "heading": "Unknown",
    "content": "Energy"
  },
  {
    "heading": "Unknown",
    "content": "Consistency"
  },
  {
    "heading": "Completeness",
    "content": "0.7\n0.2\n0.1"
  },
  {
    "heading": "Table 3: Score Weights Example",
    "content": "is the most energy-intensive method, reaching over 1.4 kg \ud835\udc36\ud835\udc422e."
  },
  {
    "heading": "The NS method, which selects only 6 out of 10 clients without",
    "content": "data removal, proves to be more efficient, reducing emissions by\napproximately 1.0 kg \ud835\udc36\ud835\udc422e. The SR method involves fewer nodes\nthan the Baseline; however, its emissions remain substantial due\nto the number of nodes engaged. Specifically, in Configuration 1,\nSR selects 10 clients, similar to the Baseline, but applies data re-\nmoval. To meet the required total data volume of 0.6, additional\nclient nodes must participate in the FL training. The MSR method\nemploys the same set and number of nodes as Node Selection but\ntrains exclusively on clean data. This difference impacts the num-\nber of epochs required and increases the overall training duration,\nleading to higher carbon emissions. This behavior is attributed to\nthe early stopping technique: training on clean data results in a\nconsistent reduction of evaluation loss after each round, preventing\npremature termination of the training process. In contrast, training\nwith dirty data causes fluctuations in loss, triggering early stopping\nand reducing the number of epochs executed."
  },
  {
    "heading": "In Configuration 1, all methods successfully met the accuracy",
    "content": "threshold, except for a single experiment using the MSR approach.\nAdditionally, every experiment demonstrated a reduction in carbon\nemissions compared to the Baseline. Among the proposed methods,\nthe NS algorithm appears to be the most effective, achieving the\nbest balance between accuracy and energy efficiency. However,\nthe MSR method exhibits a slight improvement in accuracy while\nmaintaining a comparable level of carbon emissions.\n6.2"
  },
  {
    "heading": "Unknown",
    "content": "Configuration 2"
  },
  {
    "heading": "The second evaluation experiment was conducted using Configu-",
    "content": "ration 2 from Tab. 4, paired with the TwoLeadECG dataset from\nTab. 2. The measured accuracy estimation resulted in 0.70, while\nthe carbon emissions generated during computation amounted to\n0.071 kg\ud835\udc36\ud835\udc422e. As in the previous experiment, the desired accuracy\nthreshold was set to 0.85."
  },
  {
    "heading": "The pattern observed in Fig. 9 closely resembles the one de-",
    "content": "scribed in Sec. 6.1 regarding accuracy results. The Baseline exhibits\nthe worst performance among all approaches, failing to meet the\nrequired accuracy in one of the experiments. The reduction in re-\nsource usage, particularly through data removal, proves beneficial\nand leads to improved performance in this FL environment. Notably,\nthe NS and MSR methods selected 5 clients, whereas the SR method\nrequired all 8 clients defined in Configuration 2."
  },
  {
    "heading": "Unknown",
    "content": "Figure 9: Configuration 2 Accuracy Results."
  },
  {
    "heading": "Figure 10: Configuration 2 Carbon Emissions Results.",
    "content": "In Configuration 2, specific characteristics of the dataset must be\nhighlighted. The TwoLeadECG dataset used in this experiment con-\ntains only 1,039 samples with a sequence length of 82, as outlined\nin Tab. 2. Given that these samples are distributed across 8 nodes,\nthe overall dataset size per node remains low. Consequently, the\nreduction in carbon emissions achieved by the proposed methods\nis limited. Compared to the Baseline in Sec. 6.1, the Baseline in this\nexperiment produces lower carbon emissions. However, the \ud835\udc36\ud835\udc422\nemissions of the SR method exceed those of the Baseline due to\nthe selection of all available nodes to meet the target data volume\nrequirement introduced in Sec. 5.3. In fact, in this scenario, data\nremoval and the use of clean data prevent early stopping, resulting\nin a higher number of training epochs, as previously observed in the\nvalidation of Configuration 1. The MSR algorithm delivers results\nsimilar to the NS method, selecting identical nodes and achieving\nan average reduction in emissions of 10%."
  },
  {
    "heading": "Unknown",
    "content": "9"
  },
  {
    "heading": "Unknown",
    "content": "Configuration ID"
  },
  {
    "heading": "Unknown",
    "content": "Power (kWh)"
  },
  {
    "heading": "Unknown",
    "content": "Location"
  },
  {
    "heading": "Unknown",
    "content": "Data Volume"
  },
  {
    "heading": "Unknown",
    "content": "Consistency"
  },
  {
    "heading": "Unknown",
    "content": "Completeness"
  },
  {
    "heading": "Configuration 1",
    "content": "350"
  },
  {
    "heading": "Finland",
    "content": "0.11\n0.90\n0.90\n10"
  },
  {
    "heading": "Germany",
    "content": "0.07\n0.90\n0.90\n75"
  },
  {
    "heading": "Portugal",
    "content": "0.064\n0.95\n0.80\n250"
  },
  {
    "heading": "Portugal",
    "content": "0.08\n0.70\n0.70\n100"
  },
  {
    "heading": "Canada",
    "content": "0.12\n0.95\n0.50\n350"
  },
  {
    "heading": "California",
    "content": "0.075\n0.95\n0.50\n300"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.09\n0.60\n0.90\n75"
  },
  {
    "heading": "Finland",
    "content": "0.08\n0.95\n0.95\n30"
  },
  {
    "heading": "California",
    "content": "0.068\n0.80\n0.80\n10"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.094\n0.90\n0.85\n100"
  },
  {
    "heading": "Germany",
    "content": "0.088\n0.85\n0.93\n250"
  },
  {
    "heading": "Finland",
    "content": "0.061\n0.93\n0.91"
  },
  {
    "heading": "Configuration 2",
    "content": "350"
  },
  {
    "heading": "Finland",
    "content": "0.18\n0.94\n0.90\n10"
  },
  {
    "heading": "Germany",
    "content": "0.10\n0.80\n0.95\n75"
  },
  {
    "heading": "Portugal",
    "content": "0.20\n0.95\n0.87\n250"
  },
  {
    "heading": "Portugal",
    "content": "0.12\n0.70\n0.85\n100"
  },
  {
    "heading": "Canada",
    "content": "0.10\n0.95\n0.80\n300"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.15\n0.60\n0.90\n75"
  },
  {
    "heading": "Finland",
    "content": "0.09\n0.97\n0.75\n10"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.06\n0.90\n0.80"
  },
  {
    "heading": "Configuration 3",
    "content": "350"
  },
  {
    "heading": "Finland",
    "content": "0.18\n0.78\n0.80\n10"
  },
  {
    "heading": "Germany",
    "content": "0.10\n0.87\n0.89\n75"
  },
  {
    "heading": "Portugal",
    "content": "0.20\n0.93\n0.95\n250"
  },
  {
    "heading": "Portugal",
    "content": "0.12\n0.70\n0.70\n100"
  },
  {
    "heading": "Canada",
    "content": "0.10\n0.91\n0.80\n350"
  },
  {
    "heading": "California",
    "content": "0.10\n0.95\n0.70\n300"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.05\n0.82\n0.82\n75"
  },
  {
    "heading": "Finland",
    "content": "0.05\n0.95\n0.95\n30"
  },
  {
    "heading": "California",
    "content": "0.04\n0.90\n0.90\n10"
  },
  {
    "heading": "Bosnia Herzegovina",
    "content": "0.06\n0.98\n0.98"
  },
  {
    "heading": "Unknown",
    "content": "Table 4: FL Configuration Data for Three Scenarios."
  },
  {
    "heading": "In Configuration 2, all recommended configurations success-",
    "content": "fully met the accuracy threshold. However, not all of them reduced\nthe carbon footprint compared to the Baseline, as the SR method\nfailed in this regard. The MSR approach demonstrated notable im-\nprovements in accuracy while maintaining a carbon emissions level\ncomparable to the NS method.\n6.3"
  },
  {
    "heading": "Configuration 3",
    "content": "In Configuration 3, the task proves to be more complex than in\nConfigurations 1 and 2, likely due to the larger number of training\nsamples and the increased number of classes. This complexity is\nevident when observing the maximum accuracy value, which does\nnot exceed 0.66, as shown in Fig. 11. Additionally, Configuration 3\nresults in the highest carbon emissions among all observed config-\nurations, as illustrated in Fig. 12. The accuracy estimation yields\na value of 0.54, while the carbon emissions generated for the esti-\nmation amount to 0.025 kg\ud835\udc36\ud835\udc422e. For this experiment, the accuracy\nthreshold is set to 0.60, a target that exceeds the accuracy achieved\nin five of the experiments conducted using the Baseline approach.\nThe pattern shown in Fig. 11 is similar to the ones already de-\nscribed. The Baseline shows the worst performance, failing to sat-\nisfy the required accuracy 5 out of 8 times. The usage of fewer\nresources, especially applying data removal is beneficial and leads"
  },
  {
    "heading": "Figure 11: Configuration 3 Accuracy Results.",
    "content": "to an improvement in performance in this FL environment. The\nNS and the MSR methods have selected only 2 nodes, while the SR\nmethod selected 3 clients to satisfy the data volume requirement."
  },
  {
    "heading": "All the methods show improvements in accuracy compared to the",
    "content": "Baseline, while still failing to reach the required accuracy in some\nexperiments (NS reaches the goal 5 out of 8 times, while SR and"
  },
  {
    "heading": "MSR succeed 6 out of 8 times).",
    "content": "10"
  },
  {
    "heading": "Figure 12: Configuration 3 Energy Results.",
    "content": "In Configuration 3, the Baseline carbon emissions is relevant,\nreaching 2.5 kg\ud835\udc36\ud835\udc422e. The dataset used in Configuration 3 has more\nthan 8000 samples to train, resulting in the most demanding FL\ntraining compared with the previous configurations. The recom-\nmender systems significantly reduce of 80% the carbon emissions\ngeneration on average. The NS method is the most effective, reduc-\ning the number of nodes without applying removal of low quality\ndata. The MSR produces slightly larger emissions with respect to\nNS, even though it has a higher energy cost probably due to dirty\ndata removal. Training with less data should theoretically yield\nan advantage in terms of emissions. However, data removal, while\neliminating dirty data, leads to training with a reduced but cleaner\ndataset. This, in turn, helps avoid early stopping and allows for the\nexecution of more epochs, ultimately increasing the duration time\nand energy consumption."
  },
  {
    "heading": "In Configuration 3, the recommender systems presented have",
    "content": "satisfied the accuracy threshold with 70% of success, improving on\naverage the accuracy returned by the Baseline method. All of them\nhave significantly reduced the carbon impact compared to the Base-\nline. The MSR method has obtained slightly worst results compared\nwith NS in carbon emissions generation, but it has reached better\naccuracy levels.\n6.4"
  },
  {
    "heading": "Unknown",
    "content": "Final Analysis"
  },
  {
    "heading": "After comparing the three developed methods with the Baseline",
    "content": "across the proposed configurations, general conclusions and obser-\nvations can now be drawn.\nAccuracy Results. All three methods performed well in all sce-\nnarios, showing an improvement over the Baseline. The NS method\ndemonstrates slightly better results than the Baseline due to its\nprioritization of nodes with a volume satisfying the Basic Data\nVolume Percentage. This strategy retains the original (potentially\nnoisy) data. The NS method achieves a 10% improvement in accu-\nracy, meeting the accuracy threshold set by the researcher in 87%\nof the experiments. The MSR method selects the same nodes as NS\nbut applies data filtering, using only clean data during FL training.\nThis does not drastically alter the training performance compared\nto NS. In general, MSR registers an 8% accuracy improvement over\nthe Baseline, satisfying the accuracy threshold in 87% of cases. The\nSR method, which selects more nodes with clean data than the pre-\nvious approaches, yields the best accuracy results. It reports a 12%\nimprovement over the Baseline and meets the accuracy threshold\nin 92% of the experiments. From an accuracy perspective, SR is\nthe most effective method. From these observations, we can con-\nclude that the desired accuracy can be achieved and even improved\nwhile using a lower volume of data. The proposed recommender\nsystem proved effective in suggesting the appropriate data volume\nrequired to reach the target accuracy level. Furthermore, remov-\ning low-quality data enhances accuracy, but only if the target data\nvolume is maintained."
  },
  {
    "heading": "Carbon Emissions. NS achieves the best energy efficiency, re-",
    "content": "ducing carbon emissions by an average of 56% compared to the\nBaseline, with a peak reduction of approximately 90%. MSR, which\nselects the same nodes as NS but uses clean data, results in longer"
  },
  {
    "heading": "FL training due to an increased number of epochs and extended",
    "content": "duration. Consequently, its average reduction in emissions is 45%,\nwhich is lower than that of NS, though it consistently produces\nlower \ud835\udc36\ud835\udc422 emissions than the Baseline. The SR method, which\nselects more nodes (sometimes the same number as the Baseline),\nhas a lesser impact on emissions, achieving an average reduction\nof only 25%. Thus, NS outperforms the other methods in terms of\nenergy efficiency.\nOverall Analysis. As a final analysis, both NS and MSR improve\naccuracy over the Baseline while consistently minimizing energy\nconsumption, with NS performing best in carbon footprint reduc-\ntion. Meanwhile, SR excels in improving FL model accuracy but\nwith a lower improvement in the environmental impact. In conclu-\nsion, after reviewing the validation results, it can be stated that the"
  },
  {
    "heading": "NS method provides the best FL configuration recommendation.",
    "content": "Life Cycle Emissions. As detailed in Sec. 5.1, extensive experi-\nments were conducted to extract insights for developing the FL\nReduction System. The FL Simulator accounted for the highest car-\nbon emissions, as all training sessions were executed within it."
  },
  {
    "heading": "The first set of experiments analyzed data volume reduction",
    "content": "using five datasets with horizontal and vertical reduction methods.\nEach reduction type was tested across five configurations (100%,\n80%, ..., 20%) and repeated three times to mitigate randomness, re-\nsulting in 150 FL training simulations and 1.93 kg\ud835\udc36\ud835\udc422e emissions.\nThe second set focused on data quality, evaluating three quality\ndimensions across both reduction approaches using a single dataset.\nThese experiments were also repeated three times, totaling 90 sim-\nulations and 0.54 kg\ud835\udc36\ud835\udc422e emissions."
  },
  {
    "heading": "Overall, the Data-Centric FL Exploration phase generated 2.47",
    "content": "kg\ud835\udc36\ud835\udc422e. While this process is energy-intensive, it does not need\nto be repeated for every training task. Instead, the insights and FL\nReduction System developed can be reused by multiple researchers,\nmaking the methodology sustainable in the medium to long term.\n6.5"
  },
  {
    "heading": "Transparency and Reproducibility",
    "content": "To ensure transparency and reproducibility, we provide a prac-\ntical implementation of our proposed solution, including the ap-\nproach and architecture, available at the following repository: https:\n//github.com/POLIMIGreenISE/ecoFL.git. This repository contains\n11\nall necessary resources to replicate our experiments and validate\nour findings.\nThe implementation is entirely developed in Python [37], lever-\naging well-established libraries such as NumPy [16] and Pandas [35]\nfor data manipulation, including arrays, data frames, and multidi-\nmensional matrices. Scikit-Learn [36] has been employed for cre-\nating baseline machine learning models, such as linear regression.\nData visualization is facilitated using Matplotlib [20] and Stream-\nlit [21], which also serves as the framework for developing the\nsolution as a service. This approach enables seamless and imme-\ndiate execution of simulations, as well as inference and validation\nprocesses.\nOur FL Simulator is built using Flower [6], a federated learn-\ning framework that enables the simulation of multiple nodes on\na single system. Flower provides essential functionalities for pa-\nrameter transmission and aggregation during training. The deep\nlearning model used in our experiments is a ResNet architecture,\nimplemented using the Keras TensorFlow library.\nThe primary experimental task is Time Series Classification and\nseveral datasets from the UCR/UEA archive [4, 24], have been used\nduring the Data-Centric FL Exploration and Validation phase."
  },
  {
    "heading": "Comprehensive documentation and detailed execution guide-",
    "content": "lines are provided in the repository\u2019s README.md file. By making all\ncode, data, and experimental procedures publicly accessible, we aim\nto enhance the reproducibility of our findings and support further\nresearch in sustainable Federated Learning."
  },
  {
    "heading": "Unknown",
    "content": "7"
  },
  {
    "heading": "CONCLUSION",
    "content": "This work explored a data-centric approach to energy-efficient Fed-\nerated Learning (FL), focusing on optimizing data volume and node\nselection for heterogeneous and distributed datasets. By analyzing\nthe relationship between data-centric attributes, energy consump-\ntion, and FL model performance, we developed an approach that\neffectively minimizes carbon emissions while maintaining predic-\ntive accuracy."
  },
  {
    "heading": "We introduced the FL Reduction System, designed to support",
    "content": "researchers in selecting optimal FL configurations that reduce en-\nvironmental impact without compromising model performance.\nThrough extensive experimentation across three FL configurations,\nwe demonstrated that efficient data management strategies can\nsignificantly reduce computational costs. Among the proposed\nmethods, Node Selection proved the most effective in balancing\naccuracy and energy efficiency, achieving an average 56% reduction\nin carbon emissions. Minimal Smart Reduction further incor-\nporated data quality filtering, while Smart Reduction prioritized\naccuracy gains but was less efficient in reducing emissions. These\nfindings highlight the critical role of federated and cloud-based data\nmanagement in optimizing distributed ML workflows.\nBeyond individual FL training tasks, this study contributes to\ndata management support for ML by providing a reusable knowl-\nedge base for future FL deployments. The insights gained can inform\nadaptive strategies for handling heterogeneous datasets, optimizing\ncloud data management, and reducing the environmental footprint\nof FL training."
  },
  {
    "heading": "Future research could refine the proposed approach by dynami-",
    "content": "cally adjusting ranking weights for balancing energy efficiency and\ndata quality, rather than using fixed values. Additionally, exploring\nthe impact of FL hyperparameters\u2014such as batch size, early stop-\nping, number of epochs, and aggregation techniques\u2014could lead\nto further efficiency gains. Investigating data distribution effects,\nboth system-wide and within individual nodes, from an energy per-\nspective would also enhance sustainability. Finally, incorporating\nadditional data quality dimensions could further improve FL per-\nformance while reducing data volume, strengthening the impact of\nenergy-efficient data systems in federated and cloud-based learning\nenvironments."
  },
  {
    "heading": "Unknown",
    "content": "ACKNOWLEDGMENTS"
  },
  {
    "heading": "This work was supported by the project FREEDA, funded by the",
    "content": "frameworks PRIN (MUR, Italy) and by the European Union (TEADAL,\n101070186)."
  },
  {
    "heading": "REFERENCES",
    "content": "[1] 2023, July 1. Electricity Maps - Data Portal. Technical Report.\nhttps://www.\nelectricitymaps.com/data-portal\n[2] Ali Abbasi, Fan Dong, Xin Wang, Henry Leung, Jiayu Zhou, and Steve Drew. 2024.\nFedGreen: Carbon-aware Federated Learning with Model Size Adaptation. In 2024\nIEEE International Conference on Communications Workshops (ICC Workshops)."
  },
  {
    "heading": "IEEE, 1352\u20131358.",
    "content": "[3] Mart\u00edn Anselmo and Monica Vitali. 2023. A data-centric approach for reducing\ncarbon emissions in deep learning. In International Conference on Advanced"
  },
  {
    "heading": "Information Systems Engineering. Springer, 123\u2013138.",
    "content": "[4] Anthony Bagnall, Hoang Anh Dau, Jason Lines, Michael Flynn, James Large,\nAaron Bostrom, Paul Southam, and Eamonn Keogh. 2018. The UEA multivariate\ntime series classification archive, 2018. arXiv:1811.00075 [cs.LG]\n[5] Laure Berti-Equille. 2019. Learn2clean: Optimizing the Sequence of Tasks for\nWeb Data Preparation. In The World Wide Web Conference. 2580\u20132586.\n[6] Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Javier Fernandez-\nMarques, Yan Gao, Lorenzo Sani, Hei Li Kwing, Titouan Parcollet, Pedro PB de\nGusm\u00e3o, and Nicholas D Lane. 2020. Flower: A Friendly Federated Learning"
  },
  {
    "heading": "Research Framework. arXiv preprint arXiv:2007.14390 (2020).",
    "content": "[7] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex\nIngerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone\u010dn`y, Stefano Mazzocchi,\nBrendan McMahan, et al. 2019. Towards federated learning at scale: System\ndesign. Proceedings of machine learning and systems 1 (2019), 374\u2013388.\n[8] Lukas Budach, Moritz Feuerpfeil, Nina Ihde, Andrea Nathansen, Nele Noack,\nHendrik Patzlaff, Felix Naumann, and Hazar Harmouch. 2022. The effects of\ndata quality on machine learning performance. arXiv preprint arXiv:2207.14529\n(2022).\n[9] Roger Creus Castanyer, Silverio Mart\u00ednez-Fern\u00e1ndez, and Xavier Franch. 2024.\nWhich design decisions in AI-enabled mobile applications contribute to greener"
  },
  {
    "heading": "AI? Empirical Software Engineering 29, 1 (2024), 2.",
    "content": "[10] Chengliang Chai, Kaisen Jin, Nan Tang, Ju Fan, Dongjing Miao, Jiayi Wang, Yuyu\nLuo, Guoliang Li, Ye Yuan, and Guoren Wang. 2025. Cost-effective Missing Value\nImputation for Data-effective Machine Learning. ACM Transactions on Database"
  },
  {
    "heading": "Systems (2025).",
    "content": "[11] Chengliang Chai, Jiayi Wang, Yuyu Luo, Zeping Niu, and Guoliang Li. 2023. Data\nManagement for Machine Learning: A Survey. IEEE Transactions on Knowledge\nand Data Engineering 35, 5 (2023), 4646\u20134667. https://doi.org/10.1109/TKDE.\n2022.3148237\n[12] Graham Cormode, Igor L Markov, and Harish Srinivas. 2024. Private and Efficient"
  },
  {
    "heading": "Federated Numerical Aggregation.. In EDBT. 734\u2013742.",
    "content": "[13] Nathan C Frey, Dan Zhao, Simon Axelrod, Michael Jones, David Bestor, Vijay\nGadepally, Rafael G\u00f3mez-Bombarelli, and Siddharth Samsi. 2022. Energy-aware\nNeural Architecture Selection and Hyperparameter Optimization. In 2022 IEEE\nInternational Parallel and Distributed Processing Symposium Workshops (IPDPSW)."
  },
  {
    "heading": "IEEE, 732\u2013741.",
    "content": "[14] Stefanos Georgiou et al. 2022. Green ai: Do deep learning frameworks have\ndifferent costs?. In Proceedings of the 44th International Conference on Software"
  },
  {
    "heading": "Engineering. 1082\u20131094.",
    "content": "[15] Nitin Gupta, Shashank Mujumdar, Hima Patel, Satoshi Masuda, Naveen Panwar,\nSambaran Bandyopadhyay, Sameep Mehta, Shanmukha Guttula, Shazia Afzal,\nRuhi Sharma Mittal, et al. 2021. Data quality for machine learning tasks. In\nProceedings of the 27th ACM SIGKDD conference on knowledge discovery & data\nmining. 4040\u20134041.\n[16] Charles R. Harris, K. Jarrod Millman, St\u00e9fan J. van der Walt, et al. 2020. Array\nprogramming with NumPy. Nature 585, 7825 (sep 2020), 357\u2013362. https://doi.\n12\norg/10.1038/s41586-020-2649-2\n[17] Kaiming He et al. 2016. Deep Residual Learning for Image Recognition. In\nProceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n770\u2013778.\n[18] Anh-Tu Hoang, Ahmed Lekssays, Barbara Carminati, Elena Ferrari, et al. 2023.\nPrivacy-preserving Decentralized Learning of Knowledge Graph Embeddings.."
  },
  {
    "heading": "In EDBT/ICDT Workshops.",
    "content": "[19] Ting-Yun Hsiao et al. 2019. Filter-based Deep-compression with Global Average\nPooling for Convolutional Networks. Journal of Systems Architecture 95 (2019),\n9\u201318.\n[20] J. D. Hunter. 2007. Matplotlib: A 2D graphics environment. Computing in Science\n& Engineering 9, 3 (2007), 90\u201395. https://doi.org/10.1109/MCSE.2007.55\n[21] Streamlit Inc. 2024. Streamlit: The fastest way to build and share data apps.\nhttps://streamlit.io/\n[22] Abhinav Jain, Hima Patel, Lokesh Nagalapatti, Nitin Gupta, Sameep Mehta,\nShanmukha Guttula, Shashank Mujumdar, Shazia Afzal, Ruhi Sharma Mittal, and\nVitobha Munigala. 2020. Overview and importance of data quality for machine\nlearning tasks. In Proceedings of the 26th ACM SIGKDD international conference\non knowledge discovery & data mining. 3561\u20133562.\n[23] Johannes Jakubik, Michael V\u00f6ssing, Niklas K\u00fchl, Jannis Walk, and Gerhard\nSatzger. 2024. Data-centric artificial intelligence. Business & Information Systems"
  },
  {
    "heading": "Engineering 66, 4 (2024), 507\u2013515.",
    "content": "[24] Eamonn Keogh, Xiaopeng Xi, Li Wei, and Chotirat Ann Ratanamahatana. 2006.\nThe UCR time series classification/clustering homepage. URL= http://www. cs.\nucr. edu/\u02dc eamonn/time_series_data (2006).\n[25] Afsana Khan, Marijn ten Thij, and Anna Wilbik. 2025. Vertical federated learning:\nA structured literature review. Knowledge and Information Systems (2025), 1\u201339.\n[26] Will Knight. 2020. AI can do great things - if it doesn\u2019t burn the planet. Wired"
  },
  {
    "heading": "Magazine (2020).",
    "content": "[27] Nikolaos Konstantinou and Norman W Paton. 2020. Feedback Driven Improve-\nment of Data Preparation Pipelines. Information Systems 92 (2020), 101480.\n[28] Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. Federated Learn-\ning on Non-IID Data Silos: An Experimental Study. In 2022 IEEE 38th Interna-\ntional Conference on Data Engineering (ICDE). 965\u2013978. https://doi.org/10.1109/"
  },
  {
    "heading": "ICDE53745.2022.00077",
    "content": "[29] Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu, and\nBingsheng He. 2023. A Survey on Federated Learning Systems: Vision, Hype and\nReality for Data Privacy and Protection. IEEE Transactions on Knowledge and Data\nEngineering 35, 4 (2023), 3347\u20133366. https://doi.org/10.1109/TKDE.2021.3124599\n[30] Yang Liu, Yan Kang, Tianyuan Zou, Yanhong Pu, Yuanqin He, Xiaozhou Ye, Ye\nOuyang, Ya-Qin Zhang, and Qiang Yang. 2024. Vertical Federated Learning:\nConcepts, Advances, and Challenges. IEEE Transactions on Knowledge and Data\nEngineering 36, 7 (2024), 3615\u20133634. https://doi.org/10.1109/TKDE.2024.3352628\n[31] Federica Lucivero. 2020. Big data, big waste? A reflection on the environmental\nsustainability of big data initiatives. Science and Engineering Ethics 26, 2 (2020),\n1009\u20131030.\n[32] Antonio Maccioni and Riccardo Torlone. 2018. KAYAK: a Framework for just-in-\ntime Data Preparation in a Data Lake. In Advanced Information Systems Engi-\nneering: 30th International Conference, CAiSE 2018, Tallinn, Estonia, June 11-15,\n2018, Proceedings 30. Springer, 474\u2013489.\n[33] Yuyi Mao, Xianghao Yu, Kaibin Huang, Ying-Jun Angela Zhang, and Jun Zhang.\n2024. Green edge AI: A contemporary survey. Proc. IEEE (2024).\n[34] Zhuqi Miao et al. 2023. A Data Preparation Framework for Cleaning Electronic\nHealth Records and Assessing Cleaning Outcomes for Secondary Analysis. In-\nformation Systems 111 (2023), 102130.\n[35] The pandas development team. 2020. pandas-dev/pandas: Pandas. https://doi.\norg/10.5281/zenodo.3509134\n[36] Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel,\nBertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss,\nVincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. Journal\nof machine learning research 12, Oct (2011), 2825\u20132830.\n[37] Mark Pilgrim and Simon Willison. 2009. Dive Into Python 3. Vol. 2. Springer.\n[38] Neoklis Polyzotis, Sudip Roy, Steven Euijong Whang, and Martin Zinkevich.\n2018. Data lifecycle challenges in production machine learning: a survey. ACM"
  },
  {
    "heading": "Sigmod Record 47, 2 (2018), 17\u201328.",
    "content": "[39] Xinchi Qiu, Titouan Parcollet, Javier Fernandez-Marques, Pedro PB Gusmao, Yan\nGao, Daniel J Beutel, Taner Topal, Akhil Mathur, and Nicholas D Lane. 2023. A\nfirst look into the carbon footprint of federated learning. Journal of Machine"
  },
  {
    "heading": "Learning Research 24, 129 (2023), 1\u201323.",
    "content": "[40] David Rolnick et al. 2022. Tackling Climate Change with Machine Learning."
  },
  {
    "heading": "ACM Computing Surveys (CSUR) 55, 2 (2022), 1\u201396.",
    "content": "[41] Stefano Savazzi, Vittorio Rampa, Sanaz Kianoush, and Mehdi Bennis. 2022. An\nenergy and carbon footprint analysis of distributed and federated learning. IEEE\nTransactions on Green Communications and Networking 7, 1 (2022), 248\u2013264.\n[42] Roy Schwartz et al. 2020. Green AI. Commun. ACM 63, 12 (2020), 54\u201363.\n[43] Yunjung Shin et al. 2020. Practical Methods of Image Data Preprocessing for\nEnhancing the Performance of Deep Learning Based Road Crack Detection. ICIC"
  },
  {
    "heading": "Express Letters, Part B: Applications 11, 4 (2020), 373\u2013379.",
    "content": "[44] Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2020. Energy and\npolicy considerations for modern deep learning research. In Proceedings of the\nAAAI conference on artificial intelligence, Vol. 34. 13693\u201313696.\n[45] Chen Sun et al. 2017. Revisiting Unreasonable Effectiveness of Data in Deep\nLearning Era. In Proceedings of the IEEE International Conference on Computer"
  },
  {
    "heading": "Vision. 843\u2013852.",
    "content": "[46] Dipanwita Thakur, Antonella Guzzo, Giancarlo Fortino, and Francesco Piccialli.\n2025. Green Federated Learning: A new era of Green Aware AI. Comput. Surveys\n(2025).\n[47] Roberto Verdecchia, Luis Cruz, June Sallou, Michelle Lin, James Wickenden, and\nEstelle Hotellier. 2022. Data-Centric Green AI An Exploratory Empirical Study.\nIn 2022 International Conference on ICT for Sustainability (ICT4S). IEEE, 35\u201345.\nhttps://doi.org/10.1109/ict4s55073.2022.00015\n[48] Yansheng Wang, Yongxin Tong, Dingyuan Shi, and Ke Xu. 2021. An Efficient\nApproach for Cross-Silo Federated Learning to Rank. In 2021 IEEE 37th Inter-\nnational Conference on Data Engineering (ICDE). 1128\u20131139. https://doi.org/10.\n1109/ICDE51399.2021.00102\n[49] Vitor Werner de Vargas et al. 2023. Imbalanced Data Preprocessing Techniques\nfor Machine Learning: a Systematic Mapping Study. Knowledge and Information"
  },
  {
    "heading": "Systems 65, 1 (2023), 31\u201357.",
    "content": "[50] Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. 2023. Data\ncollection and quality challenges in deep learning: A data-centric ai perspective."
  },
  {
    "heading": "The VLDB Journal 32, 4 (2023), 791\u2013813.",
    "content": "[51] Philipp Wiesner, Ramin Khalili, Dennis Grinwald, Pratik Agrawal, Lauritz Tham-\nsen, and Odej Kao. 2024. Fedzero: Leveraging renewable excess energy in feder-\nated learning. In Proceedings of the 15th ACM International Conference on Future\nand Sustainable Energy Systems. 373\u2013385.\n[52] Yuncheng Wu, Naili Xing, Gang Chen, Tien Tuan Anh Dinh, Zhaojing Luo,\nBeng Chin Ooi, Xiaokui Xiao, and Meihui Zhang. 2023. Falcon: A privacy-\npreserving and interpretable vertical federated learning system. Proceedings of\nthe VLDB Endowment 16, 10 (2023), 2471\u20132484.\n[53] Daochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang,\nShaochen Zhong, and Xia Hu. 2025. Data-centric artificial intelligence: A survey."
  },
  {
    "heading": "Comput. Surveys 57, 5 (2025), 1\u201342.",
    "content": "13"
  }
]